#!/usr/bin/env python3
"""
æ—¢å­˜CSVã®ç‰¹å¾´é‡ã‚’æ›´æ–°ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
- é¨æ‰‹æˆç¸¾ï¼ˆå‹ç‡ã€é€£å¯¾ç‡ã€è¤‡å‹ç‡ï¼‰ã‚’å–å¾—
- è¿½åŠ ç‰¹å¾´é‡ã‚’è¨ˆç®—

ä½¿ã„æ–¹:
  python update_csv_features.py å¤§äº•
  python update_csv_features.py --all  # å…¨ç«¶é¦¬å ´
"""
import sys
import time
import re
from pathlib import Path
import pandas as pd
import numpy as np
import requests
from bs4 import BeautifulSoup
from datetime import datetime

# ç«¶é¦¬å ´è¨­å®š
TRACKS = {
    "å¤§äº•": {"code": "44", "data": "data/races_ohi.csv"},
    "å·å´": {"code": "45", "data": "data/races_kawasaki.csv"},
    "èˆ¹æ©‹": {"code": "43", "data": "data/races_funabashi.csv"},
    "æµ¦å’Œ": {"code": "42", "data": "data/races_urawa.csv"},
    "é–€åˆ¥": {"code": "30", "data": "data/races_monbetsu.csv"},
    "ç››å²¡": {"code": "35", "data": "data/races_morioka.csv"},
    "æ°´æ²¢": {"code": "36", "data": "data/races_mizusawa.csv"},
    "é‡‘æ²¢": {"code": "46", "data": "data/races_kanazawa.csv"},
    "ç¬ æ¾": {"code": "47", "data": "data/races_kasamatsu.csv"},
    "åå¤å±‹": {"code": "48", "data": "data/races_nagoya.csv"},
    "åœ’ç”°": {"code": "50", "data": "data/races_sonoda.csv"},
    "å§«è·¯": {"code": "51", "data": "data/races_himeji.csv"},
    "é«˜çŸ¥": {"code": "54", "data": "data/races_kochi.csv"},
    "ä½è³€": {"code": "55", "data": "data/races_saga.csv"},
}


class JockeyScraper:
    """é¨æ‰‹æˆç¸¾ã‚’å–å¾—"""
    DB_URL = "https://db.netkeiba.com"

    def __init__(self, delay=0.3):
        self.delay = delay
        self.session = requests.Session()
        self.session.headers.update({'User-Agent': 'Mozilla/5.0'})
        self.cache = {}

    def get_stats(self, jockey_id: str) -> dict:
        if jockey_id in self.cache:
            return self.cache[jockey_id]

        if pd.isna(jockey_id) or jockey_id == '':
            return {'win_rate': 0, 'place_rate': 0, 'show_rate': 0}

        url = f"{self.DB_URL}/jockey/{jockey_id}/"
        try:
            time.sleep(self.delay)
            r = self.session.get(url, timeout=30)
            r.encoding = 'EUC-JP'
            soup = BeautifulSoup(r.text, 'lxml')

            stats = {'win_rate': 0, 'place_rate': 0, 'show_rate': 0}

            # ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰æˆç¸¾ã‚’å–å¾—
            for table in soup.find_all('table'):
                rows = table.find_all('tr')
                if not rows:
                    continue

                headers = [th.get_text(strip=True) for th in rows[0].find_all(['th', 'td'])]

                # è¤‡å‹ç‡â†’é€£å¯¾ç‡â†’å‹ç‡ã®é †ã§ãƒã‚§ãƒƒã‚¯ï¼ˆèª¤ãƒãƒƒãƒé˜²æ­¢ï¼‰
                win_idx = place_idx = show_idx = -1
                for i, h in enumerate(headers):
                    if 'è¤‡å‹ç‡' in h:
                        show_idx = i
                    elif 'é€£å¯¾ç‡' in h:
                        place_idx = i
                    elif 'å‹ç‡' in h:
                        win_idx = i

                if win_idx >= 0:
                    for row in rows[1:3]:
                        cells = [c.get_text(strip=True) for c in row.find_all(['th', 'td'])]
                        if len(cells) > max(win_idx, place_idx, show_idx):
                            def parse_rate(text):
                                m = re.search(r'(\d+\.?\d*)[ï¼…%]', text)
                                return float(m.group(1)) / 100 if m else 0

                            if win_idx < len(cells):
                                stats['win_rate'] = parse_rate(cells[win_idx])
                            if place_idx < len(cells):
                                stats['place_rate'] = parse_rate(cells[place_idx])
                            if show_idx < len(cells):
                                stats['show_rate'] = parse_rate(cells[show_idx])

                            if stats['win_rate'] > 0:
                                break
                    if stats['win_rate'] > 0:
                        break

            self.cache[jockey_id] = stats
            return stats
        except Exception as e:
            print(f"    é¨æ‰‹ {jockey_id} å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {'win_rate': 0, 'place_rate': 0, 'show_rate': 0}


def add_calculated_features(df: pd.DataFrame) -> pd.DataFrame:
    """è¨ˆç®—ã§è¿½åŠ ã§ãã‚‹ç‰¹å¾´é‡ã‚’è¿½åŠ """
    df = df.copy()

    # 1. é¦¬ç•ªæ¯”ç‡ï¼ˆé¦¬ç•ª/å‡ºèµ°é ­æ•°ï¼‰- å†…å¤–ã®æœ‰åˆ©ä¸åˆ©
    if 'horse_number' in df.columns and 'field_size' in df.columns:
        df['horse_number_ratio'] = df['horse_number'] / df['field_size']

    # 2. è·é›¢ã‚«ãƒ†ã‚´ãƒªï¼ˆçŸ­è·é›¢/ä¸­è·é›¢/é•·è·é›¢ï¼‰
    if 'distance' in df.columns:
        def categorize_distance(d):
            if pd.isna(d):
                return 1
            if d < 1400:
                return 0  # çŸ­è·é›¢
            elif d < 1800:
                return 1  # ä¸­è·é›¢
            else:
                return 2  # é•·è·é›¢
        df['distance_category'] = df['distance'].apply(categorize_distance)

    # 3. å‰èµ°ç€é †å·®ï¼ˆå‰èµ°ç€é † - å¹³å‡ç€é †ï¼‰
    if 'last_rank' in df.columns and 'horse_avg_rank' in df.columns:
        df['last_rank_diff'] = df['last_rank'] - df['horse_avg_rank']
        df['last_rank_diff'] = df['last_rank_diff'].fillna(0)

    # 4. ãƒ¬ãƒ¼ã‚¹å†…ã®å‹ç‡ãƒ©ãƒ³ã‚¯
    if 'horse_win_rate' in df.columns and 'race_id' in df.columns:
        df['win_rate_rank'] = df.groupby('race_id')['horse_win_rate'].rank(ascending=False, method='min')
        df['win_rate_rank'] = df['win_rate_rank'].fillna(df['field_size'] / 2)

    # 5. é¦¬ç•ªä½ç½®ï¼ˆå†…/ä¸­/å¤–ï¼‰
    if 'horse_number' in df.columns and 'field_size' in df.columns:
        def get_position(row):
            if pd.isna(row['horse_number']) or pd.isna(row['field_size']):
                return 1
            ratio = row['horse_number'] / row['field_size']
            if ratio <= 0.33:
                return 0  # å†…
            elif ratio <= 0.66:
                return 1  # ä¸­
            else:
                return 2  # å¤–
        df['horse_position'] = df.apply(get_position, axis=1)

    return df


def update_csv(track_name: str, track_info: dict):
    """CSVã‚’æ›´æ–°"""
    csv_path = track_info['data']

    if not Path(csv_path).exists():
        print(f"âŒ CSVãŒå­˜åœ¨ã—ã¾ã›ã‚“: {csv_path}")
        return False

    print(f"\n{'='*50}")
    print(f"ğŸ‡ {track_name}ç«¶é¦¬å ´ - ç‰¹å¾´é‡æ›´æ–°")
    print(f"{'='*50}")

    # CSVèª­ã¿è¾¼ã¿
    df = pd.read_csv(csv_path)
    print(f"ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(df)}")

    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
    backup_path = csv_path.replace('.csv', f'_backup_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv')
    df.to_csv(backup_path, index=False)
    print(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {backup_path}")

    # === é¨æ‰‹æˆç¸¾ã‚’æ›´æ–° ===
    if 'jockey_id' in df.columns:
        print("\né¨æ‰‹æˆç¸¾ã‚’å–å¾—ä¸­...")
        scraper = JockeyScraper(delay=0.2)

        # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªé¨æ‰‹IDã‚’å–å¾—
        unique_jockeys = df['jockey_id'].dropna().unique()
        print(f"é¨æ‰‹æ•°: {len(unique_jockeys)}")

        # é¨æ‰‹æˆç¸¾ã‚’å–å¾—
        jockey_stats = {}
        for i, jid in enumerate(unique_jockeys):
            if i % 50 == 0:
                print(f"  {i}/{len(unique_jockeys)} å®Œäº†...")
            stats = scraper.get_stats(str(jid))
            jockey_stats[str(jid)] = stats

        # CSVã«åæ˜ 
        df['jockey_id'] = df['jockey_id'].astype(str)
        df['jockey_win_rate'] = df['jockey_id'].map(lambda x: jockey_stats.get(x, {}).get('win_rate', 0))
        df['jockey_place_rate'] = df['jockey_id'].map(lambda x: jockey_stats.get(x, {}).get('place_rate', 0))
        df['jockey_show_rate'] = df['jockey_id'].map(lambda x: jockey_stats.get(x, {}).get('show_rate', 0))

        # ç¢ºèª
        non_zero = (df['jockey_win_rate'] > 0).sum()
        print(f"é¨æ‰‹æˆç¸¾å–å¾—å®Œäº†: {non_zero}/{len(df)} ({non_zero/len(df)*100:.1f}%) ã«å€¤ã‚ã‚Š")

    # === è¨ˆç®—ç‰¹å¾´é‡ã‚’è¿½åŠ  ===
    print("\nè¨ˆç®—ç‰¹å¾´é‡ã‚’è¿½åŠ ä¸­...")
    df = add_calculated_features(df)

    new_cols = ['horse_number_ratio', 'distance_category', 'last_rank_diff', 'win_rate_rank', 'horse_position']
    added = [c for c in new_cols if c in df.columns]
    print(f"è¿½åŠ ã—ãŸç‰¹å¾´é‡: {added}")

    # === ä¿å­˜ ===
    df.to_csv(csv_path, index=False)
    print(f"\nâœ… ä¿å­˜å®Œäº†: {csv_path}")

    return True


def main():
    if len(sys.argv) < 2:
        print("ä½¿ã„æ–¹: python update_csv_features.py <ç«¶é¦¬å ´å>")
        print("        python update_csv_features.py --all")
        print(f"åˆ©ç”¨å¯èƒ½: {', '.join(TRACKS.keys())}")
        sys.exit(1)

    arg = sys.argv[1].strip()

    if arg == '--all':
        # å…¨ç«¶é¦¬å ´ã‚’æ›´æ–°
        for track_name, track_info in TRACKS.items():
            if Path(track_info['data']).exists():
                update_csv(track_name, track_info)
    elif arg in TRACKS:
        update_csv(arg, TRACKS[arg])
    else:
        print(f"âŒ ä¸æ˜ãªç«¶é¦¬å ´: {arg}")
        print(f"åˆ©ç”¨å¯èƒ½: {', '.join(TRACKS.keys())}")
        sys.exit(1)

    print("\n" + "="*50)
    print("âœ… å…¨ã¦ã®æ›´æ–°ãŒå®Œäº†ã—ã¾ã—ãŸ")
    print("æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: python train.py <ç«¶é¦¬å ´å> update")
    print("="*50)


if __name__ == "__main__":
    main()
