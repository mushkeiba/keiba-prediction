"""AUC 0.8ã‚’ç›®æŒ‡ã™æœ€é©åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ v2 - Target Encodingè¿½åŠ """
import pandas as pd
import numpy as np
import pickle
import json
from datetime import datetime
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import roc_auc_score
import lightgbm as lgb
import xgboost as xgb
from imblearn.over_sampling import SMOTE
import optuna
import warnings
warnings.filterwarnings('ignore')
optuna.logging.set_verbosity(optuna.logging.WARNING)


def target_encode(df, col, target, n_splits=5, smoothing=10):
    """Target Encoding with cross-validation to avoid leakage"""
    df = df.copy()
    global_mean = df[target].mean()

    # K-fold target encoding
    df[f'{col}_te'] = global_mean
    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)

    for train_idx, val_idx in kf.split(df, df[target]):
        train_df = df.iloc[train_idx]
        stats = train_df.groupby(col)[target].agg(['mean', 'count'])
        # Smoothing
        smooth_mean = (stats['mean'] * stats['count'] + global_mean * smoothing) / (stats['count'] + smoothing)
        df.loc[val_idx, f'{col}_te'] = df.loc[val_idx, col].map(smooth_mean).fillna(global_mean)

    return df


class AdvancedProcessorV2:
    """æ”¹è‰¯ç‰ˆå‰å‡¦ç†ã‚¯ãƒ©ã‚¹ v2 - Target Encodingè¿½åŠ """

    def __init__(self):
        self.base_features = [
            'horse_runs', 'horse_win_rate', 'horse_place_rate', 'horse_show_rate',
            'horse_avg_rank', 'horse_recent_win_rate', 'horse_recent_show_rate',
            'horse_recent_avg_rank', 'last_rank',
            'jockey_win_rate', 'jockey_place_rate', 'jockey_show_rate',
            'horse_number', 'bracket', 'age', 'weight_carried', 'distance',
            'sex_encoded', 'field_size', 'weight_diff',
            'track_condition_encoded', 'weather_encoded',
            'horse_weight', 'horse_weight_change',
            'horse_number_ratio', 'last_rank_diff', 'win_rate_rank',
            'horse_win_rate_vs_field', 'jockey_win_rate_vs_field',
            'horse_avg_rank_vs_field',
            'days_since_last_race', 'rank_trend',
            'win_streak', 'show_streak', 'recent_3_avg_rank', 'recent_10_avg_rank', 'rank_improvement',
        ]

        # Target Encodingç‰¹å¾´é‡
        self.te_features = [
            'jockey_id_te',     # é¨æ‰‹åˆ¥ã®è¤‡å‹ç‡
            'trainer_id_te',    # èª¿æ•™å¸«åˆ¥ã®è¤‡å‹ç‡
            'horse_id_te',      # é¦¬åˆ¥ã®è¤‡å‹ç‡ï¼ˆéå»å®Ÿç¸¾ï¼‰
        ]

        # è¿½åŠ ç‰¹å¾´é‡
        self.extra_features = [
            'horse_jockey_synergy',
            'form_score',
            'class_indicator',
            'horse_win_rate_std',
            'field_strength',
            'inner_outer',
            'avg_rank_percentile',
            'jockey_rank_in_race',
            # æ–°è¦è¿½åŠ 
            'odds_implied_prob',     # ã‚ªãƒƒã‚ºã‹ã‚‰è¨ˆç®—ã—ãŸæš—é»™ç¢ºç‡
            'distance_fitness',      # è·é›¢é©æ€§
            'weight_per_meter',      # æ–¤é‡/è·é›¢
            'experience_score',      # çµŒé¨“å€¤ã‚¹ã‚³ã‚¢
        ]

        self.features = self.base_features + self.te_features + self.extra_features

    def process(self, df, apply_te=True):
        df = df.copy()
        if 'rank' in df.columns:
            df = df[df['rank'].notna() & (df['rank'] > 0)]

        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆ
        df = df.reset_index(drop=True)

        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼ˆå…ˆã«ä½œæˆï¼‰
        df['target'] = (df['rank'] <= 3).astype(int)

        # === åŸºæœ¬å‰å‡¦ç† ===
        num_cols = ['rank', 'bracket', 'horse_number', 'age', 'weight_carried', 'distance',
                    'field_size', 'horse_runs', 'horse_win_rate', 'horse_place_rate',
                    'horse_show_rate', 'horse_avg_rank', 'horse_recent_win_rate',
                    'horse_recent_show_rate', 'horse_recent_avg_rank', 'last_rank',
                    'jockey_win_rate', 'jockey_place_rate', 'jockey_show_rate',
                    'horse_weight', 'weight_change']
        for c in num_cols:
            if c in df.columns:
                df[c] = pd.to_numeric(df[c], errors='coerce')

        if 'sex' in df.columns:
            df['sex_encoded'] = df['sex'].map({'ç‰¡': 0, 'ç‰': 1, 'ã‚»': 2}).fillna(0)
        else:
            df['sex_encoded'] = 0

        if 'weight_carried' in df.columns and 'race_id' in df.columns:
            df['weight_diff'] = df.groupby('race_id')['weight_carried'].transform(lambda x: x - x.mean())
        else:
            df['weight_diff'] = 0

        if 'field_size' not in df.columns:
            df['field_size'] = 12

        if 'track_condition' in df.columns:
            df['track_condition_encoded'] = df['track_condition'].map(
                {'è‰¯': 0, 'ç¨é‡': 1, 'é‡': 2, 'ä¸è‰¯': 3}
            ).fillna(0)
        else:
            df['track_condition_encoded'] = 0

        if 'weather' in df.columns:
            df['weather_encoded'] = df['weather'].map(
                {'æ™´': 0, 'æ›‡': 1, 'å°é›¨': 2, 'é›¨': 3, 'é›ª': 4}
            ).fillna(0)
        else:
            df['weather_encoded'] = 0

        if 'horse_weight' in df.columns:
            df['horse_weight'] = df['horse_weight'].fillna(450)
        else:
            df['horse_weight'] = 450

        if 'weight_change' in df.columns:
            df['horse_weight_change'] = df['weight_change'].fillna(0)
        else:
            df['horse_weight_change'] = 0

        # è¨ˆç®—ç‰¹å¾´é‡
        df['horse_number_ratio'] = (df['horse_number'] / df['field_size']).fillna(0.5)
        df['last_rank_diff'] = (df['last_rank'] - df['horse_avg_rank']).fillna(0) if 'last_rank' in df.columns and 'horse_avg_rank' in df.columns else 0

        if 'horse_win_rate' in df.columns and 'race_id' in df.columns:
            df['win_rate_rank'] = df.groupby('race_id')['horse_win_rate'].rank(ascending=False, method='min').fillna(6)
            df['horse_win_rate_vs_field'] = (df['horse_win_rate'] - df.groupby('race_id')['horse_win_rate'].transform('mean')).fillna(0)
            df['horse_win_rate_std'] = df.groupby('race_id')['horse_win_rate'].transform('std').fillna(0)
            df['field_strength'] = df.groupby('race_id')['horse_win_rate'].transform('mean').fillna(0)
        else:
            df['win_rate_rank'] = 6
            df['horse_win_rate_vs_field'] = 0
            df['horse_win_rate_std'] = 0
            df['field_strength'] = 0

        if 'jockey_win_rate' in df.columns and 'race_id' in df.columns:
            df['jockey_win_rate_vs_field'] = (df['jockey_win_rate'] - df.groupby('race_id')['jockey_win_rate'].transform('mean')).fillna(0)
            df['jockey_rank_in_race'] = df.groupby('race_id')['jockey_win_rate'].rank(ascending=False, method='min').fillna(6)
        else:
            df['jockey_win_rate_vs_field'] = 0
            df['jockey_rank_in_race'] = 6

        if 'horse_avg_rank' in df.columns and 'race_id' in df.columns:
            df['horse_avg_rank_vs_field'] = (df.groupby('race_id')['horse_avg_rank'].transform('mean') - df['horse_avg_rank']).fillna(0)
            df['avg_rank_percentile'] = df.groupby('race_id')['horse_avg_rank'].rank(pct=True).fillna(0.5)
        else:
            df['horse_avg_rank_vs_field'] = 0
            df['avg_rank_percentile'] = 0.5

        df['days_since_last_race'] = df['days_since_last_race'].fillna(30).clip(0, 365) if 'days_since_last_race' in df.columns else 30
        df['rank_trend'] = (df['horse_avg_rank'] - df['last_rank']).fillna(0) if 'last_rank' in df.columns and 'horse_avg_rank' in df.columns else 0

        df['win_streak'] = df['win_streak'] if 'win_streak' in df.columns else 0
        df['show_streak'] = df['show_streak'] if 'show_streak' in df.columns else 0
        df['recent_3_avg_rank'] = df['recent_3_avg_rank'] if 'recent_3_avg_rank' in df.columns else (df['horse_recent_avg_rank'] if 'horse_recent_avg_rank' in df.columns else 10)
        df['recent_10_avg_rank'] = df['recent_10_avg_rank'] if 'recent_10_avg_rank' in df.columns else (df['horse_avg_rank'] if 'horse_avg_rank' in df.columns else 10)
        df['rank_improvement'] = (df['horse_avg_rank'] - df['recent_3_avg_rank']).fillna(0)

        # === Target Encoding ===
        if apply_te:
            if 'jockey_id' in df.columns:
                df = target_encode(df, 'jockey_id', 'target', smoothing=20)
            else:
                df['jockey_id_te'] = df['target'].mean()

            if 'trainer_id' in df.columns:
                df = target_encode(df, 'trainer_id', 'target', smoothing=20)
            else:
                df['trainer_id_te'] = df['target'].mean()

            if 'horse_id' in df.columns:
                df = target_encode(df, 'horse_id', 'target', smoothing=5)
            else:
                df['horse_id_te'] = df['target'].mean()
        else:
            df['jockey_id_te'] = df['target'].mean()
            df['trainer_id_te'] = df['target'].mean()
            df['horse_id_te'] = df['target'].mean()

        # === è¿½åŠ ç‰¹å¾´é‡ ===
        df['horse_jockey_synergy'] = df['horse_win_rate'].fillna(0) * df['jockey_win_rate'].fillna(0) * 100

        df['form_score'] = (
            df['horse_recent_win_rate'].fillna(0) * 0.3 +
            df['horse_recent_show_rate'].fillna(0) * 0.3 +
            (1 - df['horse_recent_avg_rank'].fillna(10) / 15) * 0.2 +
            df['rank_trend'].fillna(0) / 10 * 0.2
        )

        df['class_indicator'] = df['horse_win_rate'].fillna(0) * np.log1p(df['horse_runs'].fillna(0))

        df['inner_outer'] = df.apply(
            lambda x: (x['horse_number'] / x['field_size']) * (1 if x['distance'] < 1600 else 0.5)
            if pd.notna(x.get('distance')) and x['field_size'] > 0 else 0.5,
            axis=1
        )

        # ã‚ªãƒƒã‚ºã‹ã‚‰æš—é»™ç¢ºç‡ï¼ˆã‚ªãƒƒã‚ºãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰
        if 'win_odds' in df.columns:
            df['odds_implied_prob'] = 1 / df['win_odds'].clip(1.01, 100)
        else:
            df['odds_implied_prob'] = 0.1

        # è·é›¢é©æ€§ï¼ˆé¦¬ã®å¹³å‡ç€é †ã¨è·é›¢ã®çµ„ã¿åˆã‚ã›ï¼‰
        df['distance_fitness'] = df['horse_avg_rank'].fillna(10) / (df['distance'].fillna(1600) / 1000)

        # æ–¤é‡/è·é›¢
        df['weight_per_meter'] = df['weight_carried'].fillna(55) / (df['distance'].fillna(1600) / 100)

        # çµŒé¨“å€¤ã‚¹ã‚³ã‚¢
        df['experience_score'] = np.log1p(df['horse_runs'].fillna(0)) * df['horse_show_rate'].fillna(0)

        # ä¸è¶³ç‰¹å¾´é‡ã‚’è£œå®Œ
        for f in self.features:
            if f not in df.columns:
                df[f] = 0

        return df


def objective(trial, X_tr, y_tr, X_te, y_te):
    """Optunaç›®çš„é–¢æ•°"""
    params = {
        'objective': 'binary',
        'metric': 'auc',
        'verbose': -1,
        'num_leaves': trial.suggest_int('num_leaves', 30, 150),
        'learning_rate': trial.suggest_float('learning_rate', 0.02, 0.15),
        'min_child_samples': trial.suggest_int('min_child_samples', 20, 80),
        'reg_alpha': trial.suggest_float('reg_alpha', 1e-6, 5.0, log=True),
        'reg_lambda': trial.suggest_float('reg_lambda', 1e-6, 5.0, log=True),
        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 0.95),
        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 0.95),
        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),
        'max_depth': trial.suggest_int('max_depth', 4, 10),
        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 50, 200),
    }

    model = lgb.train(
        params,
        lgb.Dataset(X_tr, y_tr),
        num_boost_round=500,
        valid_sets=[lgb.Dataset(X_te, y_te)],
        callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]
    )

    pred = model.predict(X_te)
    return roc_auc_score(y_te, pred)


def train_optimized(df, features, n_trials=100):
    """æœ€é©åŒ–ä»˜ãå­¦ç¿’"""
    X, y = df[features].fillna(-1), df['target']
    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

    # SMOTE
    try:
        smote = SMOTE(random_state=42, k_neighbors=5)
        X_tr_resampled, y_tr_resampled = smote.fit_resample(X_tr, y_tr)
        print(f"  SMOTE: {len(y_tr)} -> {len(y_tr_resampled)}")
    except:
        X_tr_resampled, y_tr_resampled = X_tr, y_tr

    # Optuna
    print(f"  Optunaæœ€é©åŒ–ä¸­ï¼ˆ{n_trials}è©¦è¡Œï¼‰...")
    study = optuna.create_study(direction='maximize')
    study.optimize(
        lambda trial: objective(trial, X_tr_resampled, y_tr_resampled, X_te, y_te),
        n_trials=n_trials,
        show_progress_bar=True
    )

    best_params = study.best_params
    best_params['objective'] = 'binary'
    best_params['metric'] = 'auc'
    best_params['verbose'] = -1

    print(f"  Best LGB: num_leaves={best_params['num_leaves']}, lr={best_params['learning_rate']:.4f}, depth={best_params['max_depth']}")

    # LightGBM
    lgb_model = lgb.train(
        best_params,
        lgb.Dataset(X_tr_resampled, y_tr_resampled),
        num_boost_round=1500,
        valid_sets=[lgb.Dataset(X_te, y_te)],
        callbacks=[lgb.early_stopping(150), lgb.log_evaluation(0)]
    )
    lgb_pred = lgb_model.predict(X_te)
    lgb_auc = roc_auc_score(y_te, lgb_pred)
    print(f"  LightGBM AUC: {lgb_auc:.4f}")

    # XGBoost
    xgb_model = xgb.XGBClassifier(
        objective='binary:logistic',
        eval_metric='auc',
        max_depth=best_params['max_depth'],
        learning_rate=best_params['learning_rate'],
        subsample=best_params['bagging_fraction'],
        colsample_bytree=best_params['feature_fraction'],
        reg_alpha=best_params['reg_alpha'],
        reg_lambda=best_params['reg_lambda'],
        n_estimators=1500,
        early_stopping_rounds=150,
        random_state=42,
        verbosity=0
    )
    xgb_model.fit(X_tr_resampled, y_tr_resampled, eval_set=[(X_te, y_te)], verbose=False)
    xgb_pred = xgb_model.predict_proba(X_te)[:, 1]
    xgb_auc = roc_auc_score(y_te, xgb_pred)
    print(f"  XGBoost AUC: {xgb_auc:.4f}")

    # Ensemble
    best_weight, best_auc = 0.5, 0
    for w in np.arange(0.3, 0.8, 0.05):
        pred = w * lgb_pred + (1 - w) * xgb_pred
        auc = roc_auc_score(y_te, pred)
        if auc > best_auc:
            best_auc = auc
            best_weight = w

    print(f"  Ensemble AUC: {best_auc:.4f} (LGB:{best_weight:.2f})")

    return {
        'lgb': lgb_model,
        'xgb': xgb_model,
        'lgb_weight': best_weight,
        'type': 'weighted_ensemble',
        'best_params': best_params
    }, best_auc


def main():
    import sys

    track_name = sys.argv[1] if len(sys.argv) > 1 else "å¤§äº•"
    n_trials = int(sys.argv[2]) if len(sys.argv) > 2 else 100

    TRACKS = {
        "å¤§äº•": {"csv": "data/races_ohi.csv", "model": "models/model_ohi.pkl", "meta": "models/model_ohi_meta.json"},
        "å·å´": {"csv": "data/races_kawasaki.csv", "model": "models/model_kawasaki.pkl", "meta": "models/model_kawasaki_meta.json"},
    }

    track = TRACKS.get(track_name)
    if not track:
        print(f"ã‚¨ãƒ©ãƒ¼: {track_name} ã¯æœªå¯¾å¿œ")
        sys.exit(1)

    old_auc = None
    try:
        with open(track["meta"], 'r', encoding='utf-8') as f:
            old_auc = json.load(f).get('auc')
    except:
        pass

    print("=" * 60)
    print(f"AUC 0.8 ç›®æ¨™æœ€é©åŒ– v2: {track_name}")
    print("  - Target Encodingè¿½åŠ ")
    print("  - æ–°è¦ç‰¹å¾´é‡è¿½åŠ ")
    print("  - é•·ã‚ã®early stopping")
    print("=" * 60)

    df = pd.read_csv(track["csv"])
    print(f"ãƒ‡ãƒ¼ã‚¿: {len(df)}ä»¶")

    processor = AdvancedProcessorV2()
    df_processed = processor.process(df)
    print(f"å‡¦ç†å¾Œ: {len(df_processed)}ä»¶")
    print(f"ç‰¹å¾´é‡: {len(processor.features)}å€‹")

    print()
    model, auc = train_optimized(df_processed, processor.features, n_trials)

    print()
    print("ä¿å­˜ä¸­...")
    with open(track["model"], 'wb') as f:
        pickle.dump({'model': model, 'features': processor.features}, f)

    race_dates = df['race_date'].dropna().astype(int).astype(str)
    min_date, max_date = race_dates.min(), race_dates.max()

    meta = {
        'track_name': track_name,
        'trained_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'data_count': len(df),
        'race_count': int(df['race_id'].nunique()),
        'date_range': {
            'from': f"{min_date[:4]}-{min_date[4:6]}-{min_date[6:8]}",
            'to': f"{max_date[:4]}-{max_date[4:6]}-{max_date[6:8]}"
        },
        'auc': round(auc, 4),
        'features': processor.features
    }
    with open(track["meta"], 'w', encoding='utf-8') as f:
        json.dump(meta, f, ensure_ascii=False, indent=2)

    print()
    print("=" * 60)
    if old_auc:
        print(f"æ—§AUC: {old_auc:.4f}")
    print(f"æ–°AUC: {auc:.4f}")
    if old_auc:
        print(f"æ”¹å–„: {(auc - old_auc) * 100:+.2f}%")

    if auc >= 0.8:
        print("ğŸ‰ AUC 0.8 é”æˆï¼")
    else:
        print(f"ç›®æ¨™ã¾ã§: {(0.8 - auc) * 100:.2f}%")
    print("=" * 60)


if __name__ == "__main__":
    main()
