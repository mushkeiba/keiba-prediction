# åœ°æ–¹ç«¶é¦¬ äºˆæ¸¬API
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import Optional
import pandas as pd
import numpy as np
import pickle
import requests
from bs4 import BeautifulSoup
import re
import time
import random
from datetime import datetime
import os
import json
from pathlib import Path
from collections import defaultdict
import asyncio

# ========== ãƒ¢ãƒ‡ãƒ«ç”¨ã‚«ã‚¹ã‚¿ãƒ ã‚¯ãƒ©ã‚¹ ==========
# pickleã§ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€éš›ã«å¿…è¦
class TargetEncoderSafe:
    """ãƒªãƒ¼ã‚¯ã—ãªã„Target Encoderï¼ˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ã¿ã§çµ±è¨ˆä½œæˆï¼‰"""

    def __init__(self, smoothing=10):
        self.smoothing = smoothing
        self.global_mean = None
        self.mappings = {}

    def fit(self, train_df, cols, target):
        """å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ã¿ã§çµ±è¨ˆã‚’ä½œæˆ"""
        self.global_mean = train_df[target].mean()

        for col in cols:
            stats = train_df.groupby(col)[target].agg(['mean', 'count'])
            smooth_mean = (stats['mean'] * stats['count'] + self.global_mean * self.smoothing) / \
                         (stats['count'] + self.smoothing)
            self.mappings[col] = smooth_mean.to_dict()

        return self

    def transform(self, df, cols):
        """å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆã§ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å¤‰æ›"""
        df = df.copy()
        for col in cols:
            te_col = f'{col}_te'
            df[te_col] = df[col].map(self.mappings.get(col, {})).fillna(self.global_mean)
        return df


def create_features_v3(df):
    """
    v3ç‰¹å¾´é‡ä½œæˆï¼ˆäººæ°—ãƒ™ãƒ¼ã‚¹ - çš„ä¸­ç‡77%é”æˆï¼‰
    å¸‚å ´ã®çŸ¥æµï¼ˆã‚ªãƒƒã‚ºï¼‰ã‚’æ´»ç”¨ã—ãŸã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
    """
    df = df.copy()

    # æ•°å€¤å¤‰æ›
    num_cols = ['horse_win_rate', 'horse_show_rate', 'last_rank',
                'jockey_win_rate', 'field_size', 'win_odds', 'last_3f']
    for c in num_cols:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors='coerce')

    # äººæ°—ï¼ˆæœ€é‡è¦ç‰¹å¾´é‡ï¼‰
    if 'win_odds' in df.columns:
        df['popularity'] = df.groupby('race_id')['win_odds'].rank(ascending=True)
        df['odds_implied_prob'] = 1 / df['win_odds'].clip(lower=1)
    else:
        df['popularity'] = 5
        df['odds_implied_prob'] = 0.1

    # äººæ°—ã«å¯¾ã™ã‚‹å®ŸåŠ›ã®ä¹–é›¢
    if 'horse_show_rate' in df.columns:
        df['show_rate_rank'] = df.groupby('race_id')['horse_show_rate'].rank(ascending=False)
        df['value_gap'] = df['show_rate_rank'] - df['popularity']
    else:
        df['value_gap'] = 0

    # ä¸ŠãŒã‚Š3Fé †ä½
    if 'last_3f' in df.columns:
        df['last_3f_rank'] = df.groupby('race_id')['last_3f'].rank(ascending=True)
    else:
        df['last_3f_rank'] = 5

    # ç‰¹å¾´é‡ãƒªã‚¹ãƒˆï¼ˆv3ãƒ¢ãƒ‡ãƒ«ã¨åŒã˜é †åºï¼‰
    features = [
        'popularity', 'odds_implied_prob', 'value_gap',
        'horse_show_rate', 'jockey_win_rate', 'last_rank',
        'last_3f_rank', 'field_size'
    ]

    # æ¬ æåŸ‹ã‚
    defaults = {
        'popularity': 5, 'odds_implied_prob': 0.1, 'value_gap': 0,
        'horse_show_rate': 0.27, 'jockey_win_rate': 0.1, 'last_rank': 5,
        'last_3f_rank': 5, 'field_size': 11
    }
    for f in features:
        if f in df.columns:
            df[f] = df[f].fillna(defaults.get(f, 0))
        else:
            df[f] = defaults.get(f, 0)

    return df, features


def create_features_v8(df):
    """
    v8ç‰¹å¾´é‡ä½œæˆï¼ˆã‚ªãƒƒã‚ºé™¤å¤– + éå»ãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰
    - å›åç‡108-110%é”æˆ
    - ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ãªã—
    """
    df = df.copy()

    # æ•°å€¤å¤‰æ›
    num_cols = [
        'horse_runs', 'horse_win_rate', 'horse_show_rate', 'horse_avg_rank',
        'horse_recent_win_rate', 'horse_recent_show_rate', 'horse_recent_avg_rank',
        'last_rank', 'jockey_win_rate', 'jockey_show_rate',
        'horse_number', 'bracket', 'age', 'weight_carried', 'distance',
        'field_size', 'horse_weight', 'weight_change'
    ]
    for c in num_cols:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors='coerce')

    # --- éå»ã‚¹ãƒ”ãƒ¼ãƒ‰æŒ‡æ•°ï¼ˆæ¨è«–æ™‚ã¯éå»ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¨ˆç®—æ¸ˆã¿ã®å€¤ã‚’ä½¿ç”¨ï¼‰ ---
    # æ¨è«–æ™‚ã¯ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã—ãŸéå»æˆç¸¾ã‹ã‚‰è¨ˆç®—
    if 'past_speed_index' not in df.columns:
        df['past_speed_index'] = 50  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    if 'past_3_speed_index' not in df.columns:
        df['past_3_speed_index'] = 50

    # --- éå»ã®ä¸ŠãŒã‚Š3F ---
    if 'past_last_3f' not in df.columns:
        df['past_last_3f'] = 40  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    if 'past_3_last_3f' not in df.columns:
        df['past_3_last_3f'] = 40

    # --- å‰èµ°çµŒéæ—¥æ•° ---
    if 'days_since_last' not in df.columns:
        df['days_since_last'] = 30  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

    # --- ãƒ¬ãƒ¼ã‚¹å†…ã§ã®ç›¸å¯¾é †ä½ ---
    df['show_rate_rank'] = df.groupby('race_id')['horse_show_rate'].rank(ascending=False)
    df['win_rate_rank'] = df.groupby('race_id')['horse_win_rate'].rank(ascending=False)
    df['jockey_rank'] = df.groupby('race_id')['jockey_win_rate'].rank(ascending=False)
    df['avg_rank_rank'] = df.groupby('race_id')['horse_avg_rank'].rank(ascending=True)
    df['past_speed_rank'] = df.groupby('race_id')['past_speed_index'].rank(ascending=False)
    df['past_3f_rank'] = df.groupby('race_id')['past_last_3f'].rank(ascending=True)

    # --- ãƒ¬ãƒ¼ã‚¹å†…ã§ã®ç›¸å¯¾å€¤ ---
    df['show_rate_vs_field'] = df['horse_show_rate'] - df.groupby('race_id')['horse_show_rate'].transform('mean')
    df['win_rate_vs_field'] = df['horse_win_rate'] - df.groupby('race_id')['horse_win_rate'].transform('mean')
    df['jockey_vs_field'] = df['jockey_win_rate'] - df.groupby('race_id')['jockey_win_rate'].transform('mean')
    df['past_speed_vs_field'] = df['past_speed_index'] - df.groupby('race_id')['past_speed_index'].transform('mean')

    # --- çµŒé¨“å€¤ã‚¹ã‚³ã‚¢ ---
    df['experience_score'] = np.log1p(df['horse_runs']) * df['horse_show_rate']

    # --- èª¿å­ã‚¹ã‚³ã‚¢ ---
    df['form_score'] = df['horse_recent_show_rate'].fillna(df['horse_show_rate'])
    df['form_trend'] = df['form_score'] - df['horse_show_rate']

    # --- å‰èµ°ã®æˆç¸¾ ---
    df['last_rank_score'] = np.where(df['last_rank'] <= 3, 1, 0)
    df['last_rank_normalized'] = df['last_rank'] / df['field_size'].clip(lower=1)

    # --- é¦¬å ´ ---
    condition_map = {'è‰¯': 0, 'ç¨é‡': 1, 'é‡': 2, 'ä¸è‰¯': 3}
    if 'track_condition' in df.columns:
        df['track_condition_code'] = df['track_condition'].map(condition_map).fillna(0)
    else:
        df['track_condition_code'] = 0

    # --- ä¼‘ã¿æ˜ã‘åŠ¹æœ ---
    df['is_fresh'] = (df['days_since_last'] >= 30).astype(int)
    df['is_long_rest'] = (df['days_since_last'] >= 60).astype(int)

    # --- ç‰¹å¾´é‡ãƒªã‚¹ãƒˆ ---
    features = [
        # ç›¸å¯¾é †ä½
        'show_rate_rank', 'win_rate_rank', 'jockey_rank', 'avg_rank_rank',
        'past_speed_rank', 'past_3f_rank',
        # ç›¸å¯¾å€¤
        'show_rate_vs_field', 'win_rate_vs_field', 'jockey_vs_field',
        'past_speed_vs_field',
        # å®Ÿç¸¾
        'horse_show_rate', 'horse_win_rate', 'horse_avg_rank',
        'jockey_win_rate', 'jockey_show_rate',
        # çµŒé¨“ãƒ»èª¿å­
        'experience_score', 'form_score', 'form_trend', 'horse_runs',
        # å‰èµ°
        'last_rank', 'last_rank_score', 'last_rank_normalized',
        # éå»ã®ã‚¹ãƒ”ãƒ¼ãƒ‰ãƒ»ã‚¿ã‚¤ãƒ 
        'past_speed_index', 'past_3_speed_index',
        'past_last_3f', 'past_3_last_3f',
        # çµŒéæ—¥æ•°
        'days_since_last', 'is_fresh', 'is_long_rest',
        # ãã®ä»–
        'field_size', 'age', 'horse_number', 'track_condition_code',
        'weight_carried', 'horse_weight'
    ]

    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    defaults = {
        'show_rate_rank': 5, 'win_rate_rank': 5, 'jockey_rank': 5, 'avg_rank_rank': 5,
        'past_speed_rank': 5, 'past_3f_rank': 5,
        'show_rate_vs_field': 0, 'win_rate_vs_field': 0, 'jockey_vs_field': 0,
        'past_speed_vs_field': 0,
        'horse_show_rate': 0.27, 'horse_win_rate': 0.1, 'horse_avg_rank': 5,
        'jockey_win_rate': 0.1, 'jockey_show_rate': 0.27,
        'experience_score': 0.5, 'form_score': 0.27, 'form_trend': 0, 'horse_runs': 10,
        'last_rank': 5, 'last_rank_score': 0, 'last_rank_normalized': 0.5,
        'past_speed_index': 50, 'past_3_speed_index': 50,
        'past_last_3f': 40, 'past_3_last_3f': 40,
        'days_since_last': 30, 'is_fresh': 0, 'is_long_rest': 0,
        'field_size': 11, 'age': 4, 'horse_number': 5, 'track_condition_code': 0,
        'weight_carried': 55, 'horse_weight': 470
    }

    for f in features:
        if f in df.columns:
            df[f] = df[f].fillna(defaults.get(f, 0))
        else:
            df[f] = defaults.get(f, 0)

    return df, features


# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—
BASE_DIR = Path(__file__).resolve().parent.parent

app = FastAPI(
    title="åœ°æ–¹ç«¶é¦¬äºˆæ¸¬API",
    description="AIãŒäºˆæ¸¬ã™ã‚‹åœ°æ–¹ç«¶é¦¬ã®3ç€ä»¥å†…äºˆæ¸¬",
    version="1.0.0"
)

# CORSè¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # æœ¬ç•ªç’°å¢ƒã§ã¯é©åˆ‡ã«åˆ¶é™
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ========== ç«¶é¦¬å ´è¨­å®š ==========
# v8ãƒ¢ãƒ‡ãƒ«ï¼ˆã‚ªãƒƒã‚ºé™¤å¤–ãƒ»é–¾å€¤ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¯¾å¿œï¼‰ã‚’å„ªå…ˆä½¿ç”¨
TRACKS = {
    "44": {"name": "å¤§äº•", "model": "models/model_ohi_v8.pkl", "emoji": "ğŸŸï¸"},
    "45": {"name": "å·å´", "model": "models/model_kawasaki_v10.pkl", "emoji": "ğŸŒŠ"},
    "43": {"name": "èˆ¹æ©‹", "model": "models/model_funabashi.pkl", "emoji": "âš“"},
    "42": {"name": "æµ¦å’Œ", "model": "models/model_urawa.pkl", "emoji": "ğŸŒ¸"},
    "30": {"name": "é–€åˆ¥", "model": "models/model_monbetsu.pkl", "emoji": "ğŸ´"},
    "35": {"name": "ç››å²¡", "model": "models/model_morioka.pkl", "emoji": "â›°ï¸"},
    "36": {"name": "æ°´æ²¢", "model": "models/model_mizusawa.pkl", "emoji": "ğŸ’§"},
    "46": {"name": "é‡‘æ²¢", "model": "models/model_kanazawa.pkl", "emoji": "âœ¨"},
    "47": {"name": "ç¬ æ¾", "model": "models/model_kasamatsu.pkl", "emoji": "ğŸ‹"},
    "48": {"name": "åå¤å±‹", "model": "models/model_nagoya.pkl", "emoji": "ğŸ¯"},
    "50": {"name": "åœ’ç”°", "model": "models/model_sonoda.pkl", "emoji": "ğŸŒ³"},
    "51": {"name": "å§«è·¯", "model": "models/model_himeji.pkl", "emoji": "ğŸ°"},
    "54": {"name": "é«˜çŸ¥", "model": "models/model_kochi.pkl", "emoji": "ğŸ‹"},
    "55": {"name": "ä½è³€", "model": "models/model_saga.pkl", "emoji": "ğŸ‹"},
}

# ãƒ¢ãƒ‡ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥
model_cache = {}

# ========== v6é¸æŠçš„ãƒ™ãƒƒãƒ†ã‚£ãƒ³ã‚°è¨­å®š ==========
# ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœ: prob_diff >= 20% ã§100%è¶…ROIé”æˆ
# prob_diff = äºˆæ¸¬1ä½ã®ç¢ºç‡ - äºˆæ¸¬2ä½ã®ç¢ºç‡

# ç«¶é¦¬å ´åˆ¥ã®æ¨å¥¨ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š
SELECTIVE_BETTING_CONFIG = {
    "44": {  # å¤§äº•
        "min_prob_diff": 0.20,  # ç¢ºç‡å·®20%ä»¥ä¸Š
        "expected_roi": 1.057,  # æœŸå¾…ROI 105.7%
        "hit_rate": 0.596,      # çš„ä¸­ç‡ 59.6%
    },
    "45": {  # å·å´
        "min_prob_diff": 0.20,  # ç¢ºç‡å·®20%ä»¥ä¸Š
        "expected_roi": 1.147,  # æœŸå¾…ROI 114.7%
        "hit_rate": 0.649,      # çš„ä¸­ç‡ 64.9%
    },
    # ãã®ä»–ã¯ä¿å®ˆçš„è¨­å®š
    "default": {
        "min_prob_diff": 0.15,
        "expected_roi": 1.0,
        "hit_rate": 0.55,
    }
}

def get_betting_config(track_code: str) -> dict:
    """ç«¶é¦¬å ´ã®é¸æŠçš„ãƒ™ãƒƒãƒ†ã‚£ãƒ³ã‚°è¨­å®šã‚’å–å¾—"""
    return SELECTIVE_BETTING_CONFIG.get(track_code, SELECTIVE_BETTING_CONFIG["default"])

# æ—§è¨­å®šã¨ã®äº’æ›æ€§ï¼ˆä»–ã®ç®‡æ‰€ã§å‚ç…§ã•ã‚Œã¦ã„ã‚‹å ´åˆç”¨ï¼‰
MIN_PLACE_ODDS_FOR_ROI = {
    "44": 1.5, "45": 1.8, "43": 2.0, "42": 2.0, "30": 2.0,
    "35": 2.0, "36": 2.0, "46": 2.0, "47": 2.0, "48": 2.0,
    "50": 2.0, "51": 2.0, "54": 2.0, "55": 2.0,
}

# è³­ã‘é‡‘è¨ˆç®—ï¼ˆæœŸå¾…å€¤ã«å¿œã˜ãŸå¯å¤‰é‡‘é¡ï¼‰
def calculate_bet_amount(expected_value: float, base_bet: int = 100) -> int:
    """æœŸå¾…å€¤ã«å¿œã˜ãŸè³­ã‘é‡‘ã‚’è¨ˆç®—"""
    if expected_value <= 1.0:
        return 0  # æœŸå¾…å€¤1.0ä»¥ä¸‹ã¯è²·ã‚ãªã„
    elif expected_value <= 1.2:
        return base_bet  # 100å††
    elif expected_value <= 1.5:
        return base_bet * 2  # 200å††
    elif expected_value <= 2.0:
        return base_bet * 3  # 300å††
    else:
        return base_bet * 5  # 500å††ï¼ˆæœŸå¾…å€¤2.0è¶…ï¼‰

# ========== äºˆæ¸¬ãƒ­ã‚°ä¿å­˜ ==========
def save_prediction_log(race_id: str, track_code: str, predictions: list, metadata: dict = None):
    """äºˆæ¸¬çµæœã‚’JSONã«ä¿å­˜ï¼ˆå¾Œã§çµæœã¨ç…§åˆã™ã‚‹ãŸã‚ï¼‰"""
    try:
        # æ—¥ä»˜ã‚’æŠ½å‡ºï¼ˆrace_idã‹ã‚‰ï¼‰
        date_str = race_id[:4] + "-" + race_id[6:8] + "-" + race_id[8:10]

        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        log_dir = BASE_DIR / "prediction_logs" / date_str
        log_dir.mkdir(parents=True, exist_ok=True)

        # ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        log_data = {
            "race_id": race_id,
            "track_code": track_code,
            "track_name": TRACKS.get(track_code, {}).get("name", "ä¸æ˜"),
            "predicted_at": datetime.now().isoformat(),
            "predictions": predictions,
            "metadata": metadata or {}
        }

        # ãƒ¬ãƒ¼ã‚¹ã”ã¨ã«ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        log_file = log_dir / f"{race_id}.json"
        with open(log_file, 'w', encoding='utf-8') as f:
            json.dump(log_data, f, ensure_ascii=False, indent=2)

        print(f"Prediction log saved: {log_file}")
    except Exception as e:
        print(f"Failed to save prediction log: {e}")

# æ—§ãƒ¢ãƒ‡ãƒ«åã¨ã®äº’æ›æ€§ï¼ˆv8ãƒ¢ãƒ‡ãƒ«ãŒãªã‘ã‚Œã°æ—§ãƒ¢ãƒ‡ãƒ«ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
MODEL_ALIASES = {
    "models/model_ohi_v8.pkl": ["models/model_ohi_v8.pkl", "models/model_ohi.pkl"],
    "models/model_kawasaki_v8.pkl": ["models/model_kawasaki_v8.pkl", "models/model_kawasaki.pkl"],
    "models/model_ohi.pkl": ["models/model_ohi.pkl", "model_v2.pkl"],
}


# ========== ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯¾ç­–ãƒ˜ãƒ«ãƒ‘ãƒ¼ ==========
# User-Agentãƒªã‚¹ãƒˆï¼ˆå®Ÿéš›ã®ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰å–å¾—ï¼‰
SCRAPER_USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Safari/605.1.15',
]

def create_scraper_session():
    """ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯¾ç­–æ¸ˆã¿ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ"""
    session = requests.Session()
    ua = random.choice(SCRAPER_USER_AGENTS)
    session.headers.update({
        'User-Agent': ua,
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
        'Accept-Language': 'ja,en-US;q=0.9,en;q=0.8',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Cache-Control': 'max-age=0',
    })
    return session

def fetch_with_retry(url, encoding='EUC-JP', retries=3, delay=0.3):
    """ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ããƒ•ã‚§ãƒƒãƒï¼ˆã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³é–¢æ•°ç”¨ï¼‰"""
    time.sleep(delay + random.uniform(0, 0.3))

    for attempt in range(retries):
        try:
            session = create_scraper_session()
            r = session.get(url, timeout=30)
            r.raise_for_status()
            r.encoding = encoding
            return BeautifulSoup(r.text, 'lxml')
        except requests.exceptions.RequestException:
            if attempt < retries - 1:
                time.sleep((2 ** attempt) + random.uniform(0, 1))
            else:
                return None
    return None


# ========== ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ ==========
class NARScraper:
    BASE_URL = "https://nar.netkeiba.com"
    DB_URL = "https://db.netkeiba.com"

    # User-Agentãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ãƒªã‚¹ãƒˆï¼ˆå®Ÿéš›ã®ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰å–å¾—ï¼‰
    USER_AGENTS = [
        # Chrome (Windows)
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
        # Chrome (Mac)
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        # Firefox (Windows)
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0',
        # Safari (Mac)
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Safari/605.1.15',
        # Edge (Windows)
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0',
    ]

    def __init__(self, track_code, delay=0.5):
        self.track_code = track_code
        self.delay = delay
        self.session = requests.Session()
        self.session.verify = False  # SSLè¨¼æ˜æ›¸æ¤œè¨¼ã‚’ã‚¹ã‚­ãƒƒãƒ—
        self.horse_cache = {}
        self.jockey_cache = {}
        self._request_count = 0
        # SSLè­¦å‘Šã‚’æŠ‘åˆ¶
        import urllib3
        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
        # åˆæœŸãƒ˜ãƒƒãƒ€ãƒ¼è¨­å®š
        self._update_headers()

    def _update_headers(self, referer=None):
        """ãƒªã‚¯ã‚¨ã‚¹ãƒˆã”ã¨ã«ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æ›´æ–°ï¼ˆãƒ–ãƒ©ã‚¦ã‚¶ã‚’æ¨¡å€£ï¼‰"""
        ua = random.choice(self.USER_AGENTS)
        headers = {
            'User-Agent': ua,
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
            'Accept-Language': 'ja,en-US;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'same-origin' if referer else 'none',
            'Sec-Fetch-User': '?1',
            'Cache-Control': 'max-age=0',
        }
        if referer:
            headers['Referer'] = referer
        self.session.headers.update(headers)

    def _random_delay(self):
        """ãƒ©ãƒ³ãƒ€ãƒ ãªé…å»¶ï¼ˆäººé–“ã‚‰ã—ã„ã‚¢ã‚¯ã‚»ã‚¹é–“éš”ã‚’æ¨¡å€£ï¼‰"""
        # åŸºæœ¬é…å»¶ Â± 30%ã®ãƒ©ãƒ³ãƒ€ãƒ  + æ™‚ã€…é•·ã‚ã®ä¼‘æ†©
        jitter = self.delay * random.uniform(0.7, 1.3)
        # 10ãƒªã‚¯ã‚¨ã‚¹ãƒˆã”ã¨ã«å°‘ã—é•·ã‚ã®ä¼‘æ†©
        if self._request_count > 0 and self._request_count % 10 == 0:
            jitter += random.uniform(1.0, 2.0)
        time.sleep(jitter)
        self._request_count += 1

    def _fetch(self, url, encoding='EUC-JP', retries=3):
        """ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ããƒ•ã‚§ãƒƒãƒ"""
        referer = f"{self.BASE_URL}/" if self.BASE_URL in url else None
        self._update_headers(referer)
        self._random_delay()

        for attempt in range(retries):
            try:
                r = self.session.get(url, timeout=30)
                r.raise_for_status()
                r.encoding = encoding
                return BeautifulSoup(r.text, 'lxml')
            except requests.exceptions.RequestException as e:
                if attempt < retries - 1:
                    # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
                    wait_time = (2 ** attempt) + random.uniform(0, 1)
                    time.sleep(wait_time)
                    self._update_headers(referer)  # ãƒ˜ãƒƒãƒ€ãƒ¼æ›´æ–°
                else:
                    raise e
        return None

    def get_race_list_by_date(self, date: str) -> list:
        url = f"{self.BASE_URL}/top/race_list_sub.html?kaisai_date={date}"
        try:
            soup = self._fetch(url, encoding='UTF-8')
            ids = []
            for a in soup.find_all('a', href=True):
                m = re.search(r'race_id=(\d+)', a['href'])
                if m:
                    race_id = m.group(1)
                    if len(race_id) >= 6 and race_id[4:6] == self.track_code:
                        ids.append(race_id)
            return list(set(ids))
        except:
            return []

    def get_race_data(self, race_id: str):
        url = f"{self.BASE_URL}/race/shutuba.html?race_id={race_id}"
        try:
            soup = self._fetch(url)
            info = {'race_id': race_id}

            # ãƒ¬ãƒ¼ã‚¹å
            nm = soup.find('h1', class_='RaceName')
            if nm:
                info['race_name'] = nm.get_text(strip=True)

            # ç™ºèµ°æ™‚åˆ»
            rd = soup.find('div', class_='RaceData01')
            if rd:
                rd_text = rd.get_text()
                tm = re.search(r'(\d{1,2}):(\d{2})', rd_text)
                if tm:
                    info['start_time'] = f"{tm.group(1)}:{tm.group(2)}"
                dm = re.search(r'(\d{3,4})m', rd_text)
                if dm:
                    info['distance'] = int(dm.group(1))

                # é¦¬å ´çŠ¶æ…‹ã‚’æŠ½å‡ºï¼ˆè‰¯/ç¨é‡/é‡/ä¸è‰¯ï¼‰
                track_cond_match = re.search(r'[ãƒ€èŠ].*?[:ï¼š]\s*(è‰¯|ç¨é‡|é‡|ä¸è‰¯)', rd_text)
                if track_cond_match:
                    info['track_condition'] = track_cond_match.group(1)
                else:
                    info['track_condition'] = 'è‰¯'

                # å¤©æ°—ã‚’æŠ½å‡ºï¼ˆæ™´/æ›‡/é›¨/å°é›¨/é›ªï¼‰
                weather_match = re.search(r'å¤©æ°—[:ï¼š]\s*(æ™´|æ›‡|é›¨|å°é›¨|é›ª)', rd_text)
                if weather_match:
                    info['weather'] = weather_match.group(1)
                else:
                    info['weather'] = 'æ™´'

            # ãƒ†ãƒ¼ãƒ–ãƒ«å–å¾—
            table = soup.find('table', class_='ShutubaTable')
            if not table:
                table = soup.find('table', class_='RaceTable01')
            if not table:
                for t in soup.find_all('table'):
                    if t.find('a', href=re.compile(r'/horse/')):
                        table = t
                        break
            if not table:
                return None

            rows = []
            for tr in table.find_all('tr'):
                tds = tr.find_all('td')
                if len(tds) < 4:
                    continue

                data = info.copy()

                bracket_text = tds[0].get_text(strip=True)
                if bracket_text.isdigit():
                    data['bracket'] = int(bracket_text)
                umaban_text = tds[1].get_text(strip=True)
                if umaban_text.isdigit():
                    data['horse_number'] = int(umaban_text)

                horse_link = tr.find('a', href=re.compile(r'/horse/\d+'))
                if horse_link:
                    data['horse_name'] = horse_link.get_text(strip=True)
                    m = re.search(r'/horse/(\d+)', horse_link['href'])
                    if m:
                        data['horse_id'] = m.group(1)

                jockey_link = tr.find('a', href=re.compile(r'/jockey/'))
                if jockey_link:
                    data['jockey_name'] = jockey_link.get_text(strip=True)
                    m = re.search(r'/jockey/(?:result/recent/)?([a-zA-Z0-9]+)', jockey_link['href'])
                    if m:
                        data['jockey_id'] = m.group(1)

                # èª¿æ•™å¸«ã‚’æŠ½å‡º
                trainer_link = tr.find('a', href=re.compile(r'/trainer/'))
                if trainer_link:
                    data['trainer_name'] = trainer_link.get_text(strip=True)
                    m = re.search(r'/trainer/(?:result/recent/)?([a-zA-Z0-9]+)', trainer_link['href'])
                    if m:
                        data['trainer_id'] = m.group(1)

                # é¦¬ä½“é‡ã‚’æŠ½å‡ºï¼ˆä¾‹: 450(+4), 448(-2), 452ï¼‰
                for td in tds:
                    weight_text = td.get_text(strip=True)
                    weight_match = re.match(r'^(\d{3,4})(?:\(([+-]?\d+)\))?$', weight_text)
                    if weight_match and 300 <= int(weight_match.group(1)) <= 600:
                        data['horse_weight'] = int(weight_match.group(1))
                        if weight_match.group(2):
                            data['weight_change'] = int(weight_match.group(2))
                        else:
                            data['weight_change'] = 0
                        break

                for td in tds:
                    text = td.get_text(strip=True)
                    if re.match(r'^[ç‰¡ç‰ã‚»]\d$', text):
                        data['sex'] = text[0]
                        data['age'] = int(text[1])
                    if re.match(r'^\d{2}(\.\d)?$', text):
                        w = float(text)
                        if 45 <= w <= 65 and 'weight_carried' not in data:
                            data['weight_carried'] = w

                if data.get('horse_name'):
                    rows.append(data)

            if not rows:
                return None

            df = pd.DataFrame(rows)
            df['field_size'] = len(df)
            return df
        except Exception as e:
            print(f'Error: {e}')

    def get_all_odds(self, race_id: str) -> dict:
        """å˜å‹ãƒ»è¤‡å‹ã‚ªãƒƒã‚ºã‚’ä¸€æ‹¬å–å¾—ï¼ˆAPIå‘¼ã³å‡ºã—æœ€å°åŒ–ï¼‰"""
        result = {'win': {}, 'place': {}}

        # 1. å‡ºé¦¬è¡¨ãƒšãƒ¼ã‚¸ã‹ã‚‰å˜å‹ã‚ªãƒƒã‚ºã‚’å–å¾—ï¼ˆ1ãƒªã‚¯ã‚¨ã‚¹ãƒˆç›®ï¼‰
        shutuba_url = f"{self.BASE_URL}/race/shutuba.html?race_id={race_id}"
        try:
            soup = self._fetch(shutuba_url)
            table = soup.find('table', class_='ShutubaTable')
            if not table:
                table = soup.find('table', class_='RaceTable01')

            if table:
                for tr in table.find_all('tr'):
                    tds = tr.find_all('td')
                    if len(tds) >= 2:
                        umaban = None
                        odds_val = None

                        for i, td in enumerate(tds[:3]):
                            td_class = ' '.join(td.get('class', []))
                            text = td.get_text(strip=True)
                            if 'Umaban' in td_class or (i == 1 and text.isdigit()):
                                if text.isdigit() and 1 <= int(text) <= 18:
                                    umaban = int(text)
                                    break

                        for td in tds:
                            td_class = ' '.join(td.get('class', []))
                            if 'Popular' in td_class or 'Odds' in td_class or 'odds' in td_class.lower():
                                text = td.get_text(strip=True)
                                odds_match = re.search(r'(\d+\.?\d*)', text)
                                if odds_match:
                                    val = float(odds_match.group(1))
                                    if 1.0 <= val <= 999.9:
                                        odds_val = val
                                        break

                        if umaban and odds_val:
                            result['win'][umaban] = odds_val
        except Exception as e:
            print(f'Win odds error: {e}')

        # 2. è¤‡å‹ã‚ªãƒƒã‚ºãƒšãƒ¼ã‚¸ã‹ã‚‰å–å¾—ï¼ˆ2ãƒªã‚¯ã‚¨ã‚¹ãƒˆç›®ï¼‰
        place_url = f"{self.BASE_URL}/odds/odds_get_form.html?type=b2&race_id={race_id}"
        try:
            soup = self._fetch(place_url)
            tables = soup.find_all('table')
            if len(tables) >= 2:
                table = tables[1]
                for tr in table.find_all('tr'):
                    tds = tr.find_all('td')
                    # tdæ§‹é€ : [æ ç•ª, é¦¬ç•ª, ç©º, é¦¬å, ã‚ªãƒƒã‚º]
                    if len(tds) >= 5:
                        umaban_text = tds[1].get_text(strip=True)  # td[1]ãŒé¦¬ç•ª
                        if umaban_text.isdigit():
                            umaban = int(umaban_text)
                            # ã‚ªãƒƒã‚ºã¯æœ€å¾Œã®td
                            odds_text = tds[-1].get_text(strip=True)
                            # ã€Œ1.4 - 2.6ã€å½¢å¼ã‚’ãƒ‘ãƒ¼ã‚¹
                            odds_match = re.search(r'(\d+\.?\d*)\s*-\s*(\d+\.?\d*)', odds_text)
                            if odds_match:
                                min_odds = float(odds_match.group(1))
                                max_odds = float(odds_match.group(2))
                                result['place'][umaban] = {
                                    'min': min_odds,
                                    'max': max_odds,
                                    'avg': round((min_odds + max_odds) / 2, 2)
                                }
                            else:
                                # å˜ä¸€ã®æ•°å€¤ã®å ´åˆ
                                single_match = re.search(r'(\d+\.?\d*)', odds_text)
                                if single_match:
                                    odds_val = float(single_match.group(1))
                                    result['place'][umaban] = {
                                        'min': odds_val,
                                        'max': odds_val,
                                        'avg': odds_val
                                    }
        except Exception as e:
            print(f'Place odds error: {e}')

        return result

    def get_odds(self, race_id: str, horse_names: list = None) -> dict:
        """å˜å‹ã‚ªãƒƒã‚ºã‚’å–å¾—ï¼ˆå‡ºé¦¬è¡¨ã®äºˆæƒ³ã‚ªãƒƒã‚ºåˆ—ã‹ã‚‰ï¼‰"""
        odds_dict = {}

        # 1. å‡ºé¦¬è¡¨ãƒšãƒ¼ã‚¸ã‹ã‚‰äºˆæƒ³ã‚ªãƒƒã‚ºã‚’å–å¾—ï¼ˆæœ€ã‚‚ç¢ºå®Ÿï¼‰
        shutuba_url = f"{self.BASE_URL}/race/shutuba.html?race_id={race_id}"
        try:
            soup = self._fetch(shutuba_url)
            table = soup.find('table', class_='ShutubaTable')
            if not table:
                table = soup.find('table', class_='RaceTable01')

            if table:
                for tr in table.find_all('tr'):
                    tds = tr.find_all('td')
                    if len(tds) >= 2:
                        # é¦¬ç•ªã¯é€šå¸¸2ç•ªç›®ã®tdï¼ˆ1ç•ªç›®ã¯æ ç•ªï¼‰
                        umaban = None
                        odds_val = None

                        # é¦¬ç•ªã‚’å–å¾—ï¼ˆUmabanã‚¯ãƒ©ã‚¹ã¾ãŸã¯2ç•ªç›®ã®tdï¼‰
                        for i, td in enumerate(tds[:3]):
                            td_class = ' '.join(td.get('class', []))
                            text = td.get_text(strip=True)
                            if 'Umaban' in td_class or (i == 1 and text.isdigit()):
                                if text.isdigit() and 1 <= int(text) <= 18:
                                    umaban = int(text)
                                    break

                        # äºˆæƒ³ã‚ªãƒƒã‚ºã‚’å–å¾—ï¼ˆPopularåˆ—ã€é€šå¸¸ã¯å¾Œã‚ã®æ–¹ã®tdï¼‰
                        for td in tds:
                            td_class = ' '.join(td.get('class', []))
                            # Popularã‚¯ãƒ©ã‚¹ã¾ãŸã¯oddsé–¢é€£ã®ã‚¯ãƒ©ã‚¹ã‚’æŒã¤ã‚»ãƒ«
                            if 'Popular' in td_class or 'Odds' in td_class or 'odds' in td_class.lower():
                                text = td.get_text(strip=True)
                                odds_match = re.search(r'(\d+\.?\d*)', text)
                                if odds_match:
                                    val = float(odds_match.group(1))
                                    if 1.0 <= val <= 999.9:
                                        odds_val = val
                                        break

                        if umaban and odds_val:
                            odds_dict[umaban] = odds_val

            if odds_dict:
                print(f"DEBUG shutuba odds: {odds_dict}")
                return odds_dict
        except Exception as e:
            print(f'Shutuba odds error: {e}')

        # ã‚ªãƒƒã‚ºãƒšãƒ¼ã‚¸ã‹ã‚‰å–å¾—ã§ããªã‹ã£ãŸå ´åˆã€ã‚¹ãƒãƒ›ç‰ˆçµæœãƒšãƒ¼ã‚¸ã‹ã‚‰å…¨é¦¬ã®ã‚ªãƒƒã‚ºã‚’å–å¾—
        # ã‚¹ãƒãƒ›ç‰ˆã¯çµæœãƒ†ãƒ¼ãƒ–ãƒ«ã«å…¨é¦¬ã®å˜å‹ã‚ªãƒƒã‚ºãŒå«ã¾ã‚Œã¦ã„ã‚‹
        sp_result_url = f"https://nar.sp.netkeiba.com/race/race_result.html?race_id={race_id}"
        try:
            soup = self._fetch(sp_result_url, encoding='UTF-8')

            # ã‚¹ãƒãƒ›ç‰ˆã®çµæœãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ã‚ªãƒƒã‚ºã‚’å–å¾—
            # ãƒ†ãƒ¼ãƒ–ãƒ«å†…ã®å„è¡Œã‹ã‚‰é¦¬ç•ªã¨ã‚ªãƒƒã‚ºã‚’æŠ½å‡º
            for tr in soup.find_all('tr'):
                tds = tr.find_all('td')
                if len(tds) >= 8:
                    try:
                        # é¦¬ç•ªã‚’æ¢ã™ï¼ˆé€šå¸¸ã¯æœ€åˆã®æ–¹ã®tdï¼‰
                        umaban = None
                        odds_val = None

                        for i, td in enumerate(tds):
                            text = td.get_text(strip=True)
                            # é¦¬ç•ªï¼ˆ1-18ã®æ•°å­—ã€é€šå¸¸2æ¡ä»¥ä¸‹ï¼‰
                            if text.isdigit() and 1 <= int(text) <= 18 and umaban is None:
                                # ç€é †ã§ã¯ãªãé¦¬ç•ªã‹ã‚’ç¢ºèªï¼ˆç€é †ã¯1ã‹ã‚‰å§‹ã¾ã‚‹å°ã•ã„æ•°å­—ï¼‰
                                # classå±æ€§ã‚„dataå±æ€§ã§åˆ¤åˆ¥ã§ãã‚‹å ´åˆã‚‚ã‚ã‚‹
                                td_class = td.get('class', [])
                                if 'Umaban' in str(td_class) or i >= 1:
                                    umaban = int(text)

                        # ã‚ªãƒƒã‚ºã‚’æ¢ã™ï¼ˆå°æ•°ç‚¹ã‚’å«ã‚€æ•°å­—ï¼‰
                        for td in tds:
                            text = td.get_text(strip=True)
                            # ã‚ªãƒƒã‚ºãƒ‘ã‚¿ãƒ¼ãƒ³: "1.5" or "29.8" ãªã©
                            odds_match = re.match(r'^(\d+\.\d+)$', text)
                            if odds_match:
                                val = float(odds_match.group(1))
                                if 1.0 <= val <= 999.9:
                                    odds_val = val
                                    break

                        if umaban and odds_val:
                            odds_dict[umaban] = odds_val

                    except (ValueError, IndexError):
                        continue

            if odds_dict:
                return odds_dict

        except Exception as e:
            print(f'SP result page error: {e}')

        # æœ€å¾Œã®æ‰‹æ®µ: PCç‰ˆçµæœãƒšãƒ¼ã‚¸ã®æ‰•æˆ»é‡‘ã‹ã‚‰å‹ã¡é¦¬ã®ã¿å–å¾—
        result_url = f"{self.BASE_URL}/race/result.html?race_id={race_id}"
        try:
            soup = self._fetch(result_url)
            payout_table = soup.find('table', class_='Payout_Detail_Table')
            if payout_table:
                for tr in payout_table.find_all('tr'):
                    th = tr.find('th')
                    if th and 'å˜å‹' in th.get_text():
                        tds = tr.find_all('td')
                        if len(tds) >= 2:
                            umaban_text = tds[0].get_text(strip=True)
                            payout_text = tds[1].get_text(strip=True)
                            if umaban_text.isdigit():
                                umaban = int(umaban_text)
                                payout_match = re.search(r'([\d,]+)', payout_text)
                                if payout_match:
                                    payout = int(payout_match.group(1).replace(',', ''))
                                    odds_dict[umaban] = payout / 100
            return odds_dict
        except Exception as e:
            print(f'Result page error: {e}')
            return {}

    def get_horse_history(self, horse_id: str):
        if horse_id in self.horse_cache:
            return self.horse_cache[horse_id]

        url = f"{self.DB_URL}/horse/ajax_horse_results.html?id={horse_id}"
        try:
            time.sleep(self.delay)
            r = self.session.get(url)
            r.encoding = 'EUC-JP'
            soup = BeautifulSoup(r.text, 'lxml')

            results = []
            last_3f_times = []  # ä¸ŠãŒã‚Š3Fã‚¿ã‚¤ãƒ 
            race_dates = []  # ãƒ¬ãƒ¼ã‚¹æ—¥ä»˜

            for tr in soup.find_all('tr'):
                tds = tr.find_all('td')
                if len(tds) < 6:
                    continue

                # ç€é †ã‚’å–å¾—ï¼ˆtds[3:7]ã®ã©ã“ã‹ã«ç€é †ãŒã‚ã‚‹ï¼‰
                rank = None
                for td in tds[3:7]:
                    t = td.get_text(strip=True)
                    if t.isdigit() and 1 <= int(t) <= 20:
                        rank = int(t)
                        break

                if rank is None:
                    continue

                results.append(rank)

                # æ—¥ä»˜ã‚’å–å¾—ï¼ˆæœ€åˆã®tdã€YYYY/MM/DDå½¢å¼ï¼‰
                if len(tds) > 0:
                    date_text = tds[0].get_text(strip=True)
                    date_match = re.search(r'(\d{4})/(\d{2})/(\d{2})', date_text)
                    if date_match:
                        race_dates.append(f"{date_match.group(1)}{date_match.group(2)}{date_match.group(3)}")

                # ä¸ŠãŒã‚Š3Fã‚’å–å¾—ï¼ˆé€šå¸¸index 9-11ã‚ãŸã‚Šï¼‰
                # ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ : æ—¥ä»˜,é–‹å‚¬,R,ãƒ¬ãƒ¼ã‚¹å,æ˜ åƒ,é ­æ•°,æ ç•ª,é¦¬ç•ª,ã‚ªãƒƒã‚º,äººæ°—,ç€é †,ç€å·®,ã‚¿ã‚¤ãƒ ,ä¸ŠãŒã‚Š...
                for idx in [13, 12, 11, 10, 9]:  # å¯èƒ½æ€§ã®ã‚ã‚‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è©¦ã™
                    if len(tds) > idx:
                        l3f_text = tds[idx].get_text(strip=True)
                        # ä¸ŠãŒã‚Š3Fã¯30-50ç§’å°ï¼ˆä¾‹: 38.5, 41.2ï¼‰
                        if re.match(r'^3[0-9]\.\d$|^4[0-9]\.\d$|^5[0-2]\.\d$', l3f_text):
                            last_3f_times.append(float(l3f_text))
                            break
                else:
                    last_3f_times.append(None)

                if len(results) >= 20:
                    break

            stats = self._calc_stats(results, last_3f_times, race_dates)
            self.horse_cache[horse_id] = stats
            return stats
        except Exception as e:
            return self._empty_stats()

    def get_jockey_stats(self, jockey_id: str):
        if jockey_id in self.jockey_cache:
            return self.jockey_cache[jockey_id]

        url = f"{self.DB_URL}/jockey/{jockey_id}/"
        try:
            soup = self._fetch(url)
            stats = {'jockey_win_rate': 0, 'jockey_place_rate': 0, 'jockey_show_rate': 0}

            # ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰æˆç¸¾ã‚’å–å¾—ï¼ˆç´¯è¨ˆè¡Œã‚’æ¢ã™ï¼‰
            tables = soup.find_all('table')
            for table in tables:
                rows = table.find_all('tr')
                # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã§ã€Œå‹ç‡ã€åˆ—ã‚’æ¢ã™
                header_row = rows[0] if rows else None
                if header_row:
                    headers = [th.get_text(strip=True) for th in header_row.find_all(['th', 'td'])]
                    # å‹ç‡ã€é€£å¯¾ç‡ã€è¤‡å‹ç‡ã®åˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ¢ã™
                    # æ³¨æ„: ã€Œè¤‡å‹ç‡ã€ã«ã¯ã€Œå‹ç‡ã€ãŒå«ã¾ã‚Œã‚‹ã®ã§ã€å…ˆã«è¤‡å‹ç‡ã‚’ãƒã‚§ãƒƒã‚¯
                    win_idx = place_idx = show_idx = -1
                    for i, h in enumerate(headers):
                        if 'è¤‡å‹ç‡' in h:
                            show_idx = i
                        elif 'é€£å¯¾ç‡' in h:
                            place_idx = i
                        elif 'å‹ç‡' in h:  # è¤‡å‹ç‡ã§ãªã„å‹ç‡
                            win_idx = i

                    if win_idx >= 0:
                        # ç´¯è¨ˆè¡Œï¼ˆ2è¡Œç›®ï¼‰ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                        for row in rows[1:3]:
                            cells = row.find_all(['th', 'td'])
                            cell_texts = [c.get_text(strip=True) for c in cells]
                            if len(cell_texts) > max(win_idx, place_idx, show_idx):
                                # å…¨è§’ãƒ»åŠè§’ä¸¡æ–¹ã®ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆè¨˜å·ã«å¯¾å¿œ
                                def parse_rate(text):
                                    m = re.search(r'(\d+\.?\d*)[ï¼…%]', text)
                                    return float(m.group(1)) / 100 if m else 0

                                if win_idx >= 0 and win_idx < len(cell_texts):
                                    stats['jockey_win_rate'] = parse_rate(cell_texts[win_idx])
                                if place_idx >= 0 and place_idx < len(cell_texts):
                                    stats['jockey_place_rate'] = parse_rate(cell_texts[place_idx])
                                if show_idx >= 0 and show_idx < len(cell_texts):
                                    stats['jockey_show_rate'] = parse_rate(cell_texts[show_idx])

                                if stats['jockey_win_rate'] > 0:
                                    break
                        if stats['jockey_win_rate'] > 0:
                            break

            self.jockey_cache[jockey_id] = stats
            return stats
        except:
            return {'jockey_win_rate': 0, 'jockey_place_rate': 0, 'jockey_show_rate': 0}

    def _calc_stats(self, ranks, last_3f_times=None, race_dates=None):
        if not ranks:
            return self._empty_stats()
        total = len(ranks)
        wins = sum(1 for r in ranks if r == 1)
        place = sum(1 for r in ranks if r <= 2)
        show = sum(1 for r in ranks if r <= 3)
        recent = ranks[:5]
        r_total = len(recent)

        # é€£å‹æ•°/é€£è¤‡å‹æ•°ã‚’è¨ˆç®—ï¼ˆç›´è¿‘ã‹ã‚‰æ•°ãˆã‚‹ï¼‰
        win_streak = 0
        for r in ranks:
            if r == 1:
                win_streak += 1
            else:
                break

        show_streak = 0
        for r in ranks:
            if r <= 3:
                show_streak += 1
            else:
                break

        # ç€é †ã®æ¨™æº–åå·®ï¼ˆå®‰å®šæ€§æŒ‡æ¨™ï¼‰
        past_rank_std = np.std(ranks) if len(ranks) >= 2 else 3.0

        # ä¸ŠãŒã‚Š3Fé–¢é€£ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤: å­¦ç¿’ãƒ‡ãƒ¼ã‚¿å¹³å‡ï¼‰
        prev_last_3f = 41.2
        avg_last_3f_3races = 41.2
        avg_last_3f_5races = 41.2

        if last_3f_times:
            # æœ‰åŠ¹ãªä¸ŠãŒã‚Š3Fã®ã¿æŠ½å‡º
            valid_3f = [t for t in last_3f_times if t is not None]
            if valid_3f:
                prev_last_3f = valid_3f[0]  # ç›´è¿‘ã®ä¸ŠãŒã‚Š3F
                avg_last_3f_3races = np.mean(valid_3f[:3]) if len(valid_3f) >= 1 else 41.2
                avg_last_3f_5races = np.mean(valid_3f[:5]) if len(valid_3f) >= 1 else 41.2

        # å‰èµ°ã‹ã‚‰ã®æ—¥æ•°è¨ˆç®—
        days_since_last_race = 30  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
        if race_dates and len(race_dates) >= 1:
            try:
                from datetime import datetime
                last_race_date = datetime.strptime(race_dates[0], '%Y%m%d')
                today = datetime.now()
                days_since_last_race = (today - last_race_date).days
            except:
                pass

        return {
            'horse_runs': total,
            'horse_win_rate': wins / total,
            'horse_place_rate': place / total,
            'horse_show_rate': show / total,
            'horse_avg_rank': np.mean(ranks),
            'horse_recent_win_rate': sum(1 for r in recent if r == 1) / r_total if r_total else 0,
            'horse_recent_show_rate': sum(1 for r in recent if r <= 3) / r_total if r_total else 0,
            'horse_recent_avg_rank': np.mean(recent) if recent else 10,
            'last_rank': ranks[0] if ranks else 10,
            'win_streak': win_streak,
            'show_streak': show_streak,
            'past_rank_std': past_rank_std,
            'prev_last_3f': prev_last_3f,
            'avg_last_3f_3races': avg_last_3f_3races,
            'avg_last_3f_5races': avg_last_3f_5races,
            'days_since_last_race': days_since_last_race
        }

    def _empty_stats(self):
        return {
            'horse_runs': 0, 'horse_win_rate': 0, 'horse_place_rate': 0,
            'horse_show_rate': 0, 'horse_avg_rank': 10,
            'horse_recent_win_rate': 0, 'horse_recent_show_rate': 0,
            'horse_recent_avg_rank': 10, 'last_rank': 10,
            'win_streak': 0, 'show_streak': 0, 'past_rank_std': 3.0,
            'prev_last_3f': 41.2, 'avg_last_3f_3races': 41.2, 'avg_last_3f_5races': 41.2,
            'days_since_last_race': 30
        }

    def enrich_data(self, df):
        df = df.copy()
        if 'horse_id' in df.columns:
            horse_data = []
            for hid in df['horse_id'].dropna().unique():
                stats = self.get_horse_history(str(hid))
                stats['horse_id'] = hid
                horse_data.append(stats)
            if horse_data:
                hdf = pd.DataFrame(horse_data)
                df['horse_id'] = df['horse_id'].astype(str)
                hdf['horse_id'] = hdf['horse_id'].astype(str)
                df = df.merge(hdf, on='horse_id', how='left')

        if 'jockey_id' in df.columns:
            jockey_data = []
            for jid in df['jockey_id'].dropna().unique():
                stats = self.get_jockey_stats(str(jid))
                stats['jockey_id'] = jid
                jockey_data.append(stats)
            if jockey_data:
                jdf = pd.DataFrame(jockey_data)
                df['jockey_id'] = df['jockey_id'].astype(str)
                jdf['jockey_id'] = jdf['jockey_id'].astype(str)
                df = df.merge(jdf, on='jockey_id', how='left')
        return df


# ========== å‰å‡¦ç† ==========
class Processor:
    def __init__(self, te_encoder=None):
        self.te_encoder = te_encoder  # Target Encoderï¼ˆãƒ¢ãƒ‡ãƒ«ã‹ã‚‰å–å¾—ï¼‰
        # æ–°ãƒ¢ãƒ‡ãƒ«ï¼ˆoptimize_v2.pyï¼‰å¯¾å¿œ: 52ç‰¹å¾´é‡
        self.features = [
            # åŸºæœ¬ç‰¹å¾´é‡
            'horse_runs', 'horse_win_rate', 'horse_place_rate', 'horse_show_rate',
            'horse_avg_rank', 'horse_recent_win_rate', 'horse_recent_show_rate',
            'horse_recent_avg_rank', 'last_rank',
            'jockey_win_rate', 'jockey_place_rate', 'jockey_show_rate',
            'horse_number', 'bracket', 'age', 'weight_carried', 'distance',
            'sex_encoded', 'field_size', 'weight_diff',
            # ç’°å¢ƒç‰¹å¾´é‡
            'track_condition_encoded', 'weather_encoded',
            'horse_weight', 'horse_weight_change',
            # è¨ˆç®—ç‰¹å¾´é‡
            'horse_number_ratio', 'last_rank_diff', 'win_rate_rank',
            # ç›¸å¯¾ç‰¹å¾´é‡ï¼ˆãƒ¬ãƒ¼ã‚¹å†…ã§ã®ç›¸å¯¾çš„ãªå¼·ã•ï¼‰
            'horse_win_rate_vs_field', 'jockey_win_rate_vs_field',
            'horse_avg_rank_vs_field',
            # ä¼‘é¤Šãƒ»èª¿å­
            'days_since_last_race', 'rank_trend',
            # æ™‚ç³»åˆ—ç‰¹å¾´é‡
            'win_streak', 'show_streak', 'recent_3_avg_rank', 'recent_10_avg_rank', 'rank_improvement',
            # Target Encodingï¼ˆæ¨è«–æ™‚ã¯ã‚°ãƒ­ãƒ¼ãƒãƒ«å¹³å‡ã‚’ä½¿ç”¨ï¼‰
            'jockey_id_te', 'trainer_id_te', 'horse_id_te',
            # è¿½åŠ ç‰¹å¾´é‡ï¼ˆAUC 0.8ç›®æ¨™ã®æœ€é©åŒ–ã§è¿½åŠ ï¼‰
            'horse_jockey_synergy', 'form_score', 'class_indicator',
            'horse_win_rate_std', 'field_strength', 'inner_outer',
            'avg_rank_percentile', 'jockey_rank_in_race', 'odds_implied_prob',
            'distance_fitness', 'weight_per_meter', 'experience_score',
            # v6è¿½åŠ ç‰¹å¾´é‡ï¼ˆä¸ŠãŒã‚Š3Fé–¢é€£ï¼‰
            'prev_last_3f', 'avg_last_3f_3races', 'avg_last_3f_5races',
            'prev_last_3f_rank', 'prev_last_3f_vs_field',
            'past_rank_std', 'is_first_race'
        ]

    def process(self, df):
        df = df.copy()
        num_cols = ['bracket', 'horse_number', 'age', 'weight_carried', 'distance',
                    'field_size', 'horse_runs', 'horse_win_rate', 'horse_place_rate',
                    'horse_show_rate', 'horse_avg_rank', 'horse_recent_win_rate',
                    'horse_recent_show_rate', 'horse_recent_avg_rank', 'last_rank',
                    'jockey_win_rate', 'jockey_place_rate', 'jockey_show_rate',
                    'horse_weight', 'weight_change']
        for c in num_cols:
            if c in df.columns:
                df[c] = pd.to_numeric(df[c], errors='coerce')

        if 'sex' in df.columns:
            df['sex_encoded'] = df['sex'].map({'ç‰¡': 0, 'ç‰': 1, 'ã‚»': 2}).fillna(0)
        else:
            df['sex_encoded'] = 0

        df['track_encoded'] = 0

        if 'weight_carried' in df.columns and 'race_id' in df.columns:
            df['weight_diff'] = df.groupby('race_id')['weight_carried'].transform(lambda x: x - x.mean())
        else:
            df['weight_diff'] = 0

        if 'field_size' not in df.columns:
            if 'race_id' in df.columns:
                df['field_size'] = df.groupby('race_id')['race_id'].transform('count')
            else:
                df['field_size'] = 12

        # é¦¬å ´çŠ¶æ…‹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆè‰¯=0, ç¨é‡=1, é‡=2, ä¸è‰¯=3ï¼‰
        if 'track_condition' in df.columns:
            df['track_condition_encoded'] = df['track_condition'].map(
                {'è‰¯': 0, 'ç¨é‡': 1, 'é‡': 2, 'ä¸è‰¯': 3}
            ).fillna(0)
        else:
            df['track_condition_encoded'] = 0

        # å¤©æ°—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆæ™´=0, æ›‡=1, å°é›¨=2, é›¨=3, é›ª=4ï¼‰
        if 'weather' in df.columns:
            df['weather_encoded'] = df['weather'].map(
                {'æ™´': 0, 'æ›‡': 1, 'å°é›¨': 2, 'é›¨': 3, 'é›ª': 4}
            ).fillna(0)
        else:
            df['weather_encoded'] = 0

        # èª¿æ•™å¸«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆãƒãƒƒã‚·ãƒ¥ãƒ™ãƒ¼ã‚¹ï¼‰
        if 'trainer_id' in df.columns:
            df['trainer_encoded'] = df['trainer_id'].apply(
                lambda x: hash(str(x)) % 10000 if pd.notna(x) else 0
            )
        else:
            df['trainer_encoded'] = 0

        # é¦¬ä½“é‡ï¼ˆæ¬ æã¯450kgã§è£œå®Œï¼‰
        if 'horse_weight' in df.columns:
            df['horse_weight'] = df['horse_weight'].fillna(450)
        else:
            df['horse_weight'] = 450

        # é¦¬ä½“é‡å¢—æ¸›
        if 'weight_change' in df.columns:
            df['horse_weight_change'] = df['weight_change'].fillna(0)
        else:
            df['horse_weight_change'] = 0

        # === è¨ˆç®—ç‰¹å¾´é‡ ===
        # é¦¬ç•ªæ¯”ç‡ï¼ˆé¦¬ç•ª/å‡ºèµ°é ­æ•°ï¼‰
        if 'horse_number' in df.columns and 'field_size' in df.columns:
            df['horse_number_ratio'] = df['horse_number'] / df['field_size']
            df['horse_number_ratio'] = df['horse_number_ratio'].fillna(0.5)

        # è·é›¢ã‚«ãƒ†ã‚´ãƒªï¼ˆçŸ­è·é›¢/ä¸­è·é›¢/é•·è·é›¢ï¼‰
        if 'distance' in df.columns:
            df['distance_category'] = df['distance'].apply(
                lambda d: 0 if pd.notna(d) and d < 1400 else (2 if pd.notna(d) and d >= 1800 else 1)
            )
        else:
            df['distance_category'] = 1

        # å‰èµ°ç€é †å·®ï¼ˆå‰èµ°ç€é † - å¹³å‡ç€é †ï¼‰
        if 'last_rank' in df.columns and 'horse_avg_rank' in df.columns:
            df['last_rank_diff'] = df['last_rank'] - df['horse_avg_rank']
            df['last_rank_diff'] = df['last_rank_diff'].fillna(0)
        else:
            df['last_rank_diff'] = 0

        # ãƒ¬ãƒ¼ã‚¹å†…ã®å‹ç‡ãƒ©ãƒ³ã‚¯
        if 'horse_win_rate' in df.columns and 'race_id' in df.columns:
            df['win_rate_rank'] = df.groupby('race_id')['horse_win_rate'].rank(ascending=False, method='min')
            df['win_rate_rank'] = df['win_rate_rank'].fillna(df['field_size'] / 2)
        else:
            df['win_rate_rank'] = 6

        # === ç›¸å¯¾ç‰¹å¾´é‡ï¼ˆãƒ¬ãƒ¼ã‚¹å†…ã§ã®ç›¸å¯¾çš„ãªå¼·ã•ï¼‰===
        if 'horse_win_rate' in df.columns and 'race_id' in df.columns:
            df['field_avg_win_rate'] = df.groupby('race_id')['horse_win_rate'].transform('mean')
            df['horse_win_rate_vs_field'] = df['horse_win_rate'] - df['field_avg_win_rate']
            df['horse_win_rate_vs_field'] = df['horse_win_rate_vs_field'].fillna(0)
        else:
            df['horse_win_rate_vs_field'] = 0

        if 'jockey_win_rate' in df.columns and 'race_id' in df.columns:
            df['field_avg_jockey_win_rate'] = df.groupby('race_id')['jockey_win_rate'].transform('mean')
            df['jockey_win_rate_vs_field'] = df['jockey_win_rate'] - df['field_avg_jockey_win_rate']
            df['jockey_win_rate_vs_field'] = df['jockey_win_rate_vs_field'].fillna(0)
        else:
            df['jockey_win_rate_vs_field'] = 0

        if 'horse_avg_rank' in df.columns and 'race_id' in df.columns:
            df['field_avg_rank'] = df.groupby('race_id')['horse_avg_rank'].transform('mean')
            df['horse_avg_rank_vs_field'] = df['field_avg_rank'] - df['horse_avg_rank']
            df['horse_avg_rank_vs_field'] = df['horse_avg_rank_vs_field'].fillna(0)
        else:
            df['horse_avg_rank_vs_field'] = 0

        # === ä¼‘é¤Šæ—¥æ•° ===
        # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼ˆenrich_dataã§ãƒãƒ¼ã‚¸æ¸ˆã¿ã€æ¬ æã¯v6ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§åŸ‹ã‚ã‚‹ï¼‰
        if 'days_since_last_race' not in df.columns:
            df['days_since_last_race'] = 30

        # === ç€é †ãƒˆãƒ¬ãƒ³ãƒ‰ ===
        if 'last_rank' in df.columns and 'horse_avg_rank' in df.columns:
            df['rank_trend'] = df['horse_avg_rank'] - df['last_rank']
            df['rank_trend'] = df['rank_trend'].fillna(0)
        else:
            df['rank_trend'] = 0

        # === äº¤äº’ä½œç”¨ç‰¹å¾´é‡ï¼ˆtrain.pyã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰===
        # é¨æ‰‹Ã—ç«¶é¦¬å ´ã®ç›¸æ€§ï¼ˆãƒãƒƒã‚·ãƒ¥ãƒ™ãƒ¼ã‚¹ï¼‰
        if 'jockey_id' in df.columns and 'race_id' in df.columns:
            df['track_code'] = df['race_id'].astype(str).str[4:6]
            df['jockey_track_interaction'] = df.apply(
                lambda x: hash(str(x.get('jockey_id', '')) + str(x.get('track_code', ''))) % 10000, axis=1
            )
        else:
            df['jockey_track_interaction'] = 0

        # èª¿æ•™å¸«Ã—è·é›¢ã®ç›¸æ€§
        if 'trainer_id' in df.columns and 'distance' in df.columns:
            df['distance_cat'] = df['distance'].apply(
                lambda d: 'short' if pd.notna(d) and d < 1400 else ('long' if pd.notna(d) and d >= 1800 else 'mid')
            )
            df['trainer_distance_interaction'] = df.apply(
                lambda x: hash(str(x.get('trainer_id', '')) + str(x.get('distance_cat', ''))) % 10000, axis=1
            )
        else:
            df['trainer_distance_interaction'] = 0

        # é¨æ‰‹Ã—è·é›¢ã®ç›¸æ€§
        if 'jockey_id' in df.columns and 'distance' in df.columns:
            if 'distance_cat' not in df.columns:
                df['distance_cat'] = df['distance'].apply(
                    lambda d: 'short' if pd.notna(d) and d < 1400 else ('long' if pd.notna(d) and d >= 1800 else 'mid')
                )
            df['jockey_distance_interaction'] = df.apply(
                lambda x: hash(str(x.get('jockey_id', '')) + str(x.get('distance_cat', ''))) % 10000, axis=1
            )
        else:
            df['jockey_distance_interaction'] = 0

        # === æ™‚ç³»åˆ—å¼·åŒ–ç‰¹å¾´é‡ ===
        # é€£å‹æ•°ï¼ˆCSVã«ã‚ã‚Œã°ä½¿ç”¨ã€ãªã‘ã‚Œã°0ï¼‰
        if 'win_streak' not in df.columns:
            df['win_streak'] = 0
        if 'show_streak' not in df.columns:
            df['show_streak'] = 0

        # ç›´è¿‘3èµ°ãƒ»10èµ°å¹³å‡ç€é †
        if 'recent_3_avg_rank' not in df.columns:
            if 'horse_recent_avg_rank' in df.columns:
                df['recent_3_avg_rank'] = df['horse_recent_avg_rank']
            else:
                df['recent_3_avg_rank'] = 10
        if 'recent_10_avg_rank' not in df.columns:
            if 'horse_avg_rank' in df.columns:
                df['recent_10_avg_rank'] = df['horse_avg_rank']
            else:
                df['recent_10_avg_rank'] = 10

        # ç€é †æ”¹å–„ãƒˆãƒ¬ãƒ³ãƒ‰
        if 'recent_3_avg_rank' in df.columns and 'horse_avg_rank' in df.columns:
            df['rank_improvement'] = df['horse_avg_rank'] - df['recent_3_avg_rank']
            df['rank_improvement'] = df['rank_improvement'].fillna(0)
        else:
            df['rank_improvement'] = 0

        # === Target Encoding ===
        if self.te_encoder is not None:
            # ãƒ¢ãƒ‡ãƒ«ã®te_encoderã‚’ä½¿ç”¨ã—ã¦å®Ÿéš›ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’é©ç”¨
            te_cols = ['jockey_id', 'trainer_id', 'horse_id']
            for col in te_cols:
                te_col = f'{col}_te'
                if col in df.columns and col in self.te_encoder.mappings:
                    df[te_col] = df[col].map(self.te_encoder.mappings[col]).fillna(self.te_encoder.global_mean)
                else:
                    df[te_col] = self.te_encoder.global_mean
        else:
            # te_encoderãŒãªã„å ´åˆã¯ã‚°ãƒ­ãƒ¼ãƒãƒ«å¹³å‡ã‚’ä½¿ç”¨
            global_te_default = 0.274  # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®è¤‡å‹ç‡å¹³å‡
            df['jockey_id_te'] = global_te_default
            df['trainer_id_te'] = global_te_default
            df['horse_id_te'] = global_te_default

        # === è¿½åŠ ç‰¹å¾´é‡ï¼ˆAUC 0.8ç›®æ¨™ã®æœ€é©åŒ–ã§è¿½åŠ ï¼‰===
        # é¦¬Ã—é¨æ‰‹ã‚·ãƒŠã‚¸ãƒ¼
        if 'horse_win_rate' in df.columns and 'jockey_win_rate' in df.columns:
            df['horse_jockey_synergy'] = df['horse_win_rate'] * df['jockey_win_rate']
        else:
            df['horse_jockey_synergy'] = 0

        # ãƒ•ã‚©ãƒ¼ãƒ ã‚¹ã‚³ã‚¢ï¼ˆèª¿å­æŒ‡æ¨™ï¼‰
        if all(c in df.columns for c in ['last_rank', 'field_size', 'horse_recent_avg_rank', 'horse_win_rate']):
            df['form_score'] = (
                0.5 * (1 - df['last_rank'] / df['field_size'].clip(lower=1)) +
                0.3 * (1 - df['horse_recent_avg_rank'] / df['field_size'].clip(lower=1)) +
                0.2 * df['horse_win_rate']
            ).fillna(0)
        else:
            df['form_score'] = 0

        # ã‚¯ãƒ©ã‚¹æŒ‡æ¨™ï¼ˆå‡ºèµ°é ­æ•°/å¹³å‡ç€é †ï¼‰
        if 'field_size' in df.columns and 'horse_avg_rank' in df.columns:
            df['class_indicator'] = df['field_size'] / (df['horse_avg_rank'] + 1)
            df['class_indicator'] = df['class_indicator'].fillna(1)
        else:
            df['class_indicator'] = 1

        # å‹ç‡ã®æ¨™æº–åå·®ï¼ˆæ¨è«–æ™‚ã¯è¨ˆç®—ä¸å¯ã€0ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
        df['horse_win_rate_std'] = 0

        # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å¼·åº¦ï¼ˆãƒ¬ãƒ¼ã‚¹å†…ã®å¹³å‡å‹ç‡ï¼‰
        if 'horse_win_rate' in df.columns and 'race_id' in df.columns:
            df['field_strength'] = df.groupby('race_id')['horse_win_rate'].transform('mean')
            df['field_strength'] = df['field_strength'].fillna(0.1)
        else:
            df['field_strength'] = 0.1

        # å†…å¤–ï¼ˆé¦¬ç•ªã«ã‚ˆã‚‹æ ä½ç½®ï¼‰: 0=å†…, 1=ä¸­, 2=å¤–
        if 'horse_number' in df.columns:
            df['inner_outer'] = df['horse_number'].apply(
                lambda x: 0 if pd.notna(x) and x <= 4 else (2 if pd.notna(x) and x >= 10 else 1)
            )
        else:
            df['inner_outer'] = 1

        # å¹³å‡ç€é †ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ï¼ˆãƒ¬ãƒ¼ã‚¹å†…ã§ã®ç›¸å¯¾é †ä½ï¼‰
        if 'horse_avg_rank' in df.columns and 'race_id' in df.columns:
            df['avg_rank_percentile'] = df.groupby('race_id')['horse_avg_rank'].rank(pct=True)
            df['avg_rank_percentile'] = df['avg_rank_percentile'].fillna(0.5)
        else:
            df['avg_rank_percentile'] = 0.5

        # é¨æ‰‹ã®ãƒ¬ãƒ¼ã‚¹å†…ãƒ©ãƒ³ã‚¯
        if 'jockey_win_rate' in df.columns and 'race_id' in df.columns:
            df['jockey_rank_in_race'] = df.groupby('race_id')['jockey_win_rate'].rank(ascending=False)
            df['jockey_rank_in_race'] = df['jockey_rank_in_race'].fillna(6)
        else:
            df['jockey_rank_in_race'] = 6

        # ã‚ªãƒƒã‚ºã‹ã‚‰ã®æš—é»™çš„å‹ç‡ï¼ˆã‚ªãƒƒã‚ºãŒãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
        if 'odds' in df.columns:
            df['odds_implied_prob'] = 1 / (df['odds'].clip(lower=1) + 1)
        else:
            df['odds_implied_prob'] = 0.1  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆç´„10å€ç›¸å½“ï¼‰

        # è·é›¢é©æ€§ï¼ˆæ¨è«–æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
        df['distance_fitness'] = 1.0

        # æ–¤é‡/è·é›¢ï¼ˆè² æ‹…é‡é‡ã®åŠ¹ç‡ï¼‰
        if 'weight_carried' in df.columns and 'distance' in df.columns:
            df['weight_per_meter'] = df['weight_carried'] / (df['distance'] / 1000).clip(lower=0.1)
            df['weight_per_meter'] = df['weight_per_meter'].fillna(50)
        else:
            df['weight_per_meter'] = 50

        # çµŒé¨“ã‚¹ã‚³ã‚¢ï¼ˆå‡ºèµ°æ•°Ã—è¤‡å‹ç‡ï¼‰
        if 'horse_runs' in df.columns and 'horse_show_rate' in df.columns:
            df['experience_score'] = np.log1p(df['horse_runs']) * df['horse_show_rate']
            df['experience_score'] = df['experience_score'].fillna(0)
        else:
            df['experience_score'] = 0

        # === è¡€çµ±ç‰¹å¾´é‡ ===
        for col in ['father_win_rate', 'father_show_rate', 'bms_win_rate', 'bms_show_rate']:
            if col not in df.columns:
                df[col] = 0

        # === v6è¿½åŠ ç‰¹å¾´é‡ï¼ˆä¸ŠãŒã‚Š3Fé–¢é€£ï¼‰===
        # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã€æ¬ æå€¤ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§åŸ‹ã‚ã‚‹
        # last_3f mean=41.2, std=2.0
        if 'prev_last_3f' not in df.columns:
            df['prev_last_3f'] = 41.2
        df['prev_last_3f'] = df['prev_last_3f'].fillna(41.2)

        # éå»3èµ°ãƒ»5èµ°ã®ä¸ŠãŒã‚Š3Få¹³å‡
        if 'avg_last_3f_3races' not in df.columns:
            df['avg_last_3f_3races'] = 41.2
        df['avg_last_3f_3races'] = df['avg_last_3f_3races'].fillna(41.2)

        if 'avg_last_3f_5races' not in df.columns:
            df['avg_last_3f_5races'] = 41.2
        df['avg_last_3f_5races'] = df['avg_last_3f_5races'].fillna(41.2)

        # å‰èµ°ã‹ã‚‰ã®æ—¥æ•°ï¼ˆã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰
        if 'days_since_last_race' not in df.columns:
            df['days_since_last_race'] = 30
        df['days_since_last_race'] = df['days_since_last_race'].fillna(30)

        # å‰èµ°ã®ä¸ŠãŒã‚Š3Fé †ä½ï¼ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å†…ã§ã®ç›¸å¯¾é †ä½ï¼‰- å®Ÿãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¨ˆç®—
        if 'prev_last_3f' in df.columns:
            df['prev_last_3f_rank'] = df.groupby(level=0, group_keys=False).apply(
                lambda x: x['prev_last_3f'].rank(ascending=True)
            ).reset_index(drop=True) if len(df) > 1 else 5.5
        if 'prev_last_3f_rank' not in df.columns or df['prev_last_3f_rank'].isna().all():
            df['prev_last_3f_rank'] = 5.5
        df['prev_last_3f_rank'] = df['prev_last_3f_rank'].fillna(5.5)

        # ä¸ŠãŒã‚Š3Fã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å¹³å‡ã¨ã®å·® - å®Ÿãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¨ˆç®—
        if 'prev_last_3f' in df.columns and len(df) > 1:
            field_mean = df['prev_last_3f'].mean()
            df['prev_last_3f_vs_field'] = field_mean - df['prev_last_3f']  # é€Ÿã„ã»ã©+
        else:
            df['prev_last_3f_vs_field'] = 0
        df['prev_last_3f_vs_field'] = df['prev_last_3f_vs_field'].fillna(0)

        # éå»ç€é †ã®æ¨™æº–åå·®ï¼ˆå®‰å®šæ€§æŒ‡æ¨™ï¼‰
        if 'past_rank_std' not in df.columns:
            df['past_rank_std'] = 2.66
        df['past_rank_std'] = df['past_rank_std'].fillna(2.66)

        # åˆå‡ºèµ°ãƒ•ãƒ©ã‚°ï¼ˆå‡ºèµ°å›æ•°ãŒ0ã¾ãŸã¯1ãªã‚‰åˆå‡ºèµ°ï¼‰
        if 'is_first_race' not in df.columns:
            if 'horse_runs' in df.columns:
                df['is_first_race'] = (df['horse_runs'] <= 1).astype(int)
            else:
                df['is_first_race'] = 0

        # === v10ãƒ¢ãƒ‡ãƒ«ç”¨ç‰¹å¾´é‡ ===
        # ãƒ¬ãƒ¼ã‚¹å†…ç›¸å¯¾é †ä½
        if 'horse_show_rate' in df.columns and 'race_id' in df.columns:
            df['show_rate_rank'] = df.groupby('race_id')['horse_show_rate'].rank(ascending=False, method='min').fillna(6)
        else:
            df['show_rate_rank'] = 6

        if 'jockey_win_rate' in df.columns and 'race_id' in df.columns:
            df['jockey_rank'] = df.groupby('race_id')['jockey_win_rate'].rank(ascending=False, method='min').fillna(6)
        else:
            df['jockey_rank'] = 6

        if 'horse_avg_rank' in df.columns and 'race_id' in df.columns:
            df['avg_rank_rank'] = df.groupby('race_id')['horse_avg_rank'].rank(ascending=True, method='min').fillna(6)
        else:
            df['avg_rank_rank'] = 6

        # éå»ã‚¹ãƒ”ãƒ¼ãƒ‰æŒ‡æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ50ï¼‰
        df['past_speed_index'] = 50
        df['past_3_speed_index'] = 50
        df['past_speed_rank'] = 6

        # éå»ä¸ŠãŒã‚Š3F
        if 'prev_last_3f' in df.columns:
            df['past_last_3f'] = df['prev_last_3f'].fillna(40)
            df['past_3_last_3f'] = df['avg_last_3f_3races'].fillna(40) if 'avg_last_3f_3races' in df.columns else 40
            df['past_3f_rank'] = df.groupby('race_id')['past_last_3f'].rank(ascending=True, method='min').fillna(6) if 'race_id' in df.columns else 6
        else:
            df['past_last_3f'] = 40
            df['past_3_last_3f'] = 40
            df['past_3f_rank'] = 6

        # ç›¸å¯¾å€¤
        if 'horse_show_rate' in df.columns and 'race_id' in df.columns:
            df['show_rate_vs_field'] = df['horse_show_rate'] - df.groupby('race_id')['horse_show_rate'].transform('mean')
            df['show_rate_vs_field'] = df['show_rate_vs_field'].fillna(0)
        else:
            df['show_rate_vs_field'] = 0

        # win_rate_vs_fieldã¯horse_win_rate_vs_fieldã‹ã‚‰ã‚³ãƒ”ãƒ¼
        if 'horse_win_rate_vs_field' in df.columns:
            df['win_rate_vs_field'] = df['horse_win_rate_vs_field']
        else:
            df['win_rate_vs_field'] = 0

        if 'jockey_win_rate' in df.columns and 'race_id' in df.columns:
            df['jockey_vs_field'] = df['jockey_win_rate'] - df.groupby('race_id')['jockey_win_rate'].transform('mean')
            df['jockey_vs_field'] = df['jockey_vs_field'].fillna(0)
        else:
            df['jockey_vs_field'] = 0

        df['past_speed_vs_field'] = 0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

        # form_trend
        if 'form_score' in df.columns and 'horse_show_rate' in df.columns:
            df['form_trend'] = df['form_score'] - df['horse_show_rate']
            df['form_trend'] = df['form_trend'].fillna(0)
        else:
            df['form_trend'] = 0

        # å‰èµ°æˆç¸¾ã‚¹ã‚³ã‚¢
        if 'last_rank' in df.columns:
            df['last_rank_score'] = (df['last_rank'] <= 3).astype(int)
            df['last_rank_normalized'] = df['last_rank'] / df['field_size'].clip(lower=1) if 'field_size' in df.columns else 0.5
        else:
            df['last_rank_score'] = 0
            df['last_rank_normalized'] = 0.5

        # çµŒéæ—¥æ•°é–¢é€£
        if 'days_since_last_race' in df.columns:
            df['days_since_last'] = df['days_since_last_race'].fillna(30).clip(0, 180)
        else:
            df['days_since_last'] = 30
        df['is_fresh'] = (df['days_since_last'] >= 30).astype(int)
        df['is_long_rest'] = (df['days_since_last'] >= 60).astype(int)

        # track_condition_code (track_condition_encodedã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹)
        if 'track_condition_encoded' in df.columns:
            df['track_condition_code'] = df['track_condition_encoded']
        else:
            df['track_condition_code'] = 0

        for f in self.features:
            if f not in df.columns:
                df[f] = 0
        return df

    def get_features(self):
        return self.features


# ========== ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ ==========
def load_model(track_code: str):
    """
    ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€
    Returns: (model, features, te_encoder, version, best_threshold)
    """
    if track_code in model_cache:
        return model_cache[track_code]

    if track_code not in TRACKS:
        return None, None, None, None, None

    model_name = TRACKS[track_code]['model']

    # ã‚¨ã‚¤ãƒªã‚¢ã‚¹ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆæ—§ãƒ¢ãƒ‡ãƒ«åã¨ã®äº’æ›æ€§ï¼‰
    paths_to_try = [model_name]
    if model_name in MODEL_ALIASES:
        paths_to_try = MODEL_ALIASES[model_name]

    # pickleã§ã‚«ã‚¹ã‚¿ãƒ ã‚¯ãƒ©ã‚¹ã‚’èª­ã¿è¾¼ã‚ã‚‹ã‚ˆã†__main__ã«ç™»éŒ²
    import __main__
    __main__.TargetEncoderSafe = TargetEncoderSafe

    for model_name in paths_to_try:
        model_path = BASE_DIR / model_name
        if model_path.exists():
            with open(model_path, 'rb') as f:
                d = pickle.load(f)
            te_encoder = d.get('te_encoder')  # Target Encoderå–å¾—
            version = d.get('version', 'legacy')  # ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ³å–å¾—
            best_threshold = d.get('best_threshold', 0.15)  # v8ã®é–¾å€¤ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ0.15ï¼‰
            model_cache[track_code] = (d['model'], d['features'], te_encoder, version, best_threshold)
            return d['model'], d['features'], te_encoder, version, best_threshold
    return None, None, None, None, None


def predict_with_model(model, X):
    """ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ï¼ˆã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å¯¾å¿œï¼‰- ç¢ºç‡ã‚’è¿”ã™"""
    if isinstance(model, dict):
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã®å ´åˆ
        model_type = model.get('type', 'ensemble')
        if model_type == 'ensemble':
            # åˆ†é¡å™¨ã®å ´åˆã¯predict_probaã‚’ä½¿ç”¨ï¼ˆã‚¯ãƒ©ã‚¹1ã®ç¢ºç‡ï¼‰
            lgb_pred = model['lgb'].predict_proba(X)[:, 1]
            xgb_pred = model['xgb'].predict_proba(X)[:, 1]
            return (lgb_pred + xgb_pred) / 2
        elif model_type == 'xgb':
            return model['xgb'].predict_proba(X)[:, 1]
        elif model_type == 'lgb':
            return model['lgb'].predict_proba(X)[:, 1]
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æœ€åˆã«è¦‹ã¤ã‹ã£ãŸãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
            for key in ['lgb', 'xgb', 'model']:
                if key in model:
                    m = model[key]
                    if hasattr(m, 'predict_proba'):
                        return m.predict_proba(X)[:, 1]
                    return m.predict(X)
            raise ValueError(f"Unknown model type: {model_type}")
    else:
        # å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã®å ´åˆ
        if hasattr(model, 'predict_proba'):
            return model.predict_proba(X)[:, 1]
        return model.predict(X)


# ========== APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ==========

@app.get("/")
def root():
    return {"message": "åœ°æ–¹ç«¶é¦¬äºˆæ¸¬API", "version": "1.0.0"}


@app.get("/api/tracks")
def get_tracks():
    """åˆ©ç”¨å¯èƒ½ãªç«¶é¦¬å ´ä¸€è¦§ã‚’å–å¾—"""
    tracks = []
    for code, info in TRACKS.items():
        model_name = info['model']
        # ã‚¨ã‚¤ãƒªã‚¢ã‚¹ã‚‚å«ã‚ã¦ãƒã‚§ãƒƒã‚¯
        paths_to_check = [model_name]
        if model_name in MODEL_ALIASES:
            paths_to_check = MODEL_ALIASES[model_name]
        model_exists = any((BASE_DIR / p).exists() for p in paths_to_check)
        tracks.append({
            "code": code,
            "name": info['name'],
            "emoji": info['emoji'],
            "model_available": model_exists
        })
    return {"tracks": tracks}


class PredictRequest(BaseModel):
    track_code: str
    date: str  # YYYY-MM-DDå½¢å¼


class PredictionResult(BaseModel):
    rank: int
    number: int
    name: str
    jockey: str
    prob: float
    win_rate: float
    show_rate: float


class RaceResult(BaseModel):
    id: str
    name: str
    distance: int
    time: str
    predictions: list[PredictionResult]


@app.post("/api/predict")
def predict(request: PredictRequest):
    """äºˆæ¸¬ã‚’å®Ÿè¡Œï¼ˆäº‹å‰ç”ŸæˆJSONãŒã‚ã‚Œã°å„ªå…ˆä½¿ç”¨ï¼‰"""
    track_code = request.track_code
    date_str = request.date.replace("-", "")

    if track_code not in TRACKS:
        raise HTTPException(status_code=400, detail="ç„¡åŠ¹ãªç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰")

    # === äº‹å‰ç”ŸæˆJSONã‚’ãƒã‚§ãƒƒã‚¯ ===
    predictions_file = BASE_DIR / "predictions" / request.date / f"{track_code}.json"
    if predictions_file.exists():
        # JSONãŒå­˜åœ¨ã™ã‚Œã°èª­ã¿è¾¼ã‚“ã§è¿”ã™ï¼ˆä¸€è²«æ€§ã®ã‚ã‚‹äºˆæ¸¬ï¼‰
        with open(predictions_file, 'r', encoding='utf-8') as f:
            cached_data = json.load(f)
        # äº‹å‰ç”Ÿæˆãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã™ãƒ•ãƒ©ã‚°ã‚’è¿½åŠ 
        cached_data["from_cache"] = True
        return cached_data

    # === JSONãŒãªã„å ´åˆã¯ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° ===
    model, model_features, te_encoder, model_version, best_threshold = load_model(track_code)
    if model is None:
        raise HTTPException(
            status_code=400,
            detail=f"{TRACKS[track_code]['name']}ã®ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“"
        )

    # ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«å¿œã˜ãŸå‡¦ç†ã‚’é¸æŠ
    use_v8 = model_version == 'v8_no_leak'
    use_v3 = model_version == 'auto_optimized'

    scraper = NARScraper(track_code, delay=0.3)
    processor = Processor(te_encoder=te_encoder) if not (use_v3 or use_v8) else None

    # ãƒ¬ãƒ¼ã‚¹ä¸€è¦§å–å¾—
    race_ids = scraper.get_race_list_by_date(date_str)
    if not race_ids:
        return {"races": [], "message": "ãƒ¬ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}

    results = []
    for rid in sorted(race_ids):
        df = scraper.get_race_data(rid)
        if df is None:
            continue

        df = scraper.enrich_data(df)

        # ã‚ªãƒƒã‚ºå–å¾—ï¼ˆå˜å‹ãƒ»è¤‡å‹ã‚’ä¸€æ‹¬å–å¾—ï¼‰- v3ã§ã¯ç‰¹å¾´é‡ã«å¿…è¦
        all_odds = scraper.get_all_odds(rid)
        win_odds_dict = all_odds.get('win', {})
        place_odds_dict = all_odds.get('place', {})

        # ã‚ªãƒƒã‚ºã‚’DataFrameã«è¿½åŠ ï¼ˆv3ç‰¹å¾´é‡ã§å¿…è¦ï¼‰
        if 'horse_number' in df.columns:
            df['win_odds'] = df['horse_number'].apply(lambda x: win_odds_dict.get(int(x), 10) if pd.notna(x) else 10)

        # ç‰¹å¾´é‡ä½œæˆ
        if use_v8:
            # v8: ã‚ªãƒƒã‚ºé™¤å¤–ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼ˆå›åç‡108-110%ï¼‰
            df, features_to_use = create_features_v8(df)
        elif use_v3:
            # v3: äººæ°—ãƒ™ãƒ¼ã‚¹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼ˆçš„ä¸­ç‡77%ï¼‰
            df, features_to_use = create_features_v3(df)
        else:
            # å¾“æ¥ãƒ¢ãƒ‡ãƒ«
            df = processor.process(df)
            features_to_use = model_features

        # äºˆæ¸¬
        X = df[features_to_use].fillna(-1)
        df['prob'] = predict_with_model(model, X)
        df['pred_rank'] = df['prob'].rank(ascending=False, method='min').astype(int)
        df = df.sort_values('prob', ascending=False)

        # ãƒ¬ãƒ¼ã‚¹ç•ªå·æŠ½å‡º
        race_num = rid[-2:]
        race_name = df['race_name'].iloc[0] if 'race_name' in df.columns else f"{race_num}R"
        distance = int(df['distance'].iloc[0]) if 'distance' in df.columns else 0
        start_time = df['start_time'].iloc[0] if 'start_time' in df.columns else ""

        predictions = []
        for i, (_, row) in enumerate(df.iterrows()):  # å…¨é¦¬ã‚’è¿”ã™
            horse_num = int(row['horse_number']) if pd.notna(row.get('horse_number')) else 0
            win_odds = win_odds_dict.get(horse_num, 0)
            place_odds_data = place_odds_dict.get(horse_num, {})
            place_odds = place_odds_data.get('avg', 0) if place_odds_data else 0
            place_odds_min = place_odds_data.get('min', 0) if place_odds_data else 0
            place_odds_max = place_odds_data.get('max', 0) if place_odds_data else 0
            prob = float(row['prob'])

            # å‹ç‡ãƒ»è¤‡å‹ç‡ã‚’å–å¾—ï¼ˆ0-1ã®ç¯„å›²ã§ã‚ã‚‹ã¹ãï¼‰
            raw_win_rate = float(row.get('horse_win_rate') or 0)
            raw_show_rate = float(row.get('horse_show_rate') or 0)

            win_rate = raw_win_rate * 100
            show_rate = raw_show_rate * 100

            # æœŸå¾…å€¤è¨ˆç®—ï¼ˆè¤‡å‹ã‚ªãƒƒã‚º Ã— AIç¢ºç‡ï¼‰
            # è¤‡å‹ã‚ªãƒƒã‚ºãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ç”¨ã€ãªã‘ã‚Œã°å˜å‹/3ã§æ¨å®š
            effective_place_odds = place_odds if place_odds > 0 else (win_odds / 3 if win_odds > 0 else 0)
            expected_value = prob * effective_place_odds if effective_place_odds > 0 else 0

            # å¦™å‘³åˆ¤å®š: æœŸå¾…å€¤ > 1.0 ãªã‚‰é»’å­—æœŸå¾…
            is_value = expected_value > 1.0

            # ========== å›åç‡ãƒ™ãƒ¼ã‚¹è²·ã„ç›®åˆ¤å®š ==========
            # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœ: äºˆæ¸¬1ä½ã®ã¿ã‚’å¯¾è±¡ã€ã‚ªãƒƒã‚ºæ¡ä»¶ã§å›åç‡100%+ã‚’ç‹™ã†
            bet_layer = None
            recommended_bet = 0
            min_odds = MIN_PLACE_ODDS_FOR_ROI.get(track_code, 2.0)

            if i == 0:  # äºˆæ¸¬1ä½ã®ã¿å¯¾è±¡ï¼ˆãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã¨åŒã˜æ¡ä»¶ï¼‰
                if effective_place_odds >= min_odds:
                    # å›åç‡100%ä»¥ä¸ŠãŒæœŸå¾…ã§ãã‚‹
                    bet_layer = "roi_buy"
                    recommended_bet = calculate_bet_amount(expected_value)
                elif effective_place_odds > 0:
                    # ã‚ªãƒƒã‚ºä¸è¶³ã ãŒå‚è€ƒè¡¨ç¤º
                    bet_layer = "watch"
                    recommended_bet = 0

            predictions.append({
                "rank": i + 1,
                "number": horse_num,
                "name": row.get('horse_name', 'ä¸æ˜'),
                "jockey": row.get('jockey_name', 'ä¸æ˜'),
                "prob": round(prob, 3),
                "win_rate": round(win_rate, 1),
                "show_rate": round(show_rate, 1),
                "odds": win_odds,
                "place_odds": place_odds,
                "place_odds_min": place_odds_min,
                "place_odds_max": place_odds_max,
                "expected_value": round(expected_value, 2),
                "is_value": is_value,
                "bet_layer": bet_layer,
                "recommended_bet": recommended_bet
            })

        # ä¿¡é ¼åº¦æŒ‡æ¨™ï¼ˆprob_gapï¼‰ã‚’è¨ˆç®—
        prob_gap = 0
        if len(df) >= 2:
            sorted_probs = df['prob'].sort_values(ascending=False).values
            prob_gap = float(sorted_probs[0] - sorted_probs[1])

        results.append({
            "id": race_num,
            "name": race_name,
            "distance": distance,
            "time": start_time,
            "field_size": len(df),  # å‡ºèµ°é ­æ•°ã‚’è¿½åŠ 
            "prob_gap": round(prob_gap, 3),  # 1ä½ã¨2ä½ã®ç¢ºç‡å·®
            "predictions": predictions
        })

    # ========== é¸æŠçš„ãƒ™ãƒƒãƒ†ã‚£ãƒ³ã‚° ==========
    # v8ãƒ¢ãƒ‡ãƒ«ã®å ´åˆã¯best_thresholdã‚’ä½¿ç”¨ã€ãã‚Œä»¥å¤–ã¯v6è¨­å®šã‚’ä½¿ç”¨
    if use_v8:
        min_prob_diff = best_threshold
        expected_roi = 1.08  # v8ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœ: 108%
        strategy_name = f"v8é–¾å€¤ãƒ•ã‚£ãƒ«ã‚¿: ç¢ºç‡å·®{int(min_prob_diff*100)}%ä»¥ä¸Šã§è³¼å…¥ï¼ˆæœŸå¾…ROI {expected_roi:.0%}ï¼‰"
    else:
        config = get_betting_config(track_code)
        min_prob_diff = config["min_prob_diff"]
        expected_roi = config["expected_roi"]
        strategy_name = f"ç¢ºç‡å·®{int(min_prob_diff*100)}%ä»¥ä¸Šã§è³¼å…¥ï¼ˆæœŸå¾…ROI {expected_roi:.1%}ï¼‰"

    betting_picks = {
        "roi_buy": [],     # æ¨å¥¨è²·ã„ï¼ˆprob_diffæ¡ä»¶ã‚¯ãƒªã‚¢ï¼‰â€»ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰äº’æ›
        "v6_buy": [],      # åŒã˜å†…å®¹ï¼ˆæ—§ã‚­ãƒ¼åã€äº’æ›æ€§ï¼‰
        "v8_buy": [],      # v8ç”¨ï¼ˆæ–°ã‚­ãƒ¼åï¼‰
        "watch": [],       # æ§˜å­è¦‹ï¼ˆprob_diffä¸è¶³ï¼‰
        "total_bet": 0,
        "expected_return": 0,
        "strategy": strategy_name,
        "model_version": model_version,
        "min_prob_diff": min_prob_diff,
        "expected_roi": expected_roi,
    }

    for race in results:
        preds = race["predictions"]
        if len(preds) < 2:
            continue

        # prob_diffè¨ˆç®—ï¼ˆ1ä½ã¨2ä½ã®ç¢ºç‡å·®ï¼‰
        prob_diff = preds[0]["prob"] - preds[1]["prob"]
        top_pred = preds[0]

        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼: prob_diff >= é–¾å€¤
        if prob_diff >= min_prob_diff:
            pick = {
                "race_id": race["id"],
                "race_name": race["name"],
                "race_time": race["time"],
                "number": top_pred["number"],
                "name": top_pred["name"],
                "prob": top_pred["prob"],
                "prob_diff": round(prob_diff, 3),
                "place_odds": top_pred["place_odds"],
                "odds": top_pred["odds"],
                "recommended_bet": 100,  # å›ºå®š100å††
                "confidence": "é«˜" if prob_diff >= 0.25 else ("ä¸­" if prob_diff >= 0.15 else "ä½"),
            }
            betting_picks["v6_buy"].append(pick)
            betting_picks["v8_buy"].append(pick)
            betting_picks["roi_buy"].append(pick)  # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰äº’æ›
            betting_picks["total_bet"] += 100
            # æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³ = è³­ã‘é‡‘ Ã— æœŸå¾…ROI
            betting_picks["expected_return"] += 100 * expected_roi
        else:
            # prob_diffä¸è¶³ â†’ æ§˜å­è¦‹
            pick = {
                "race_id": race["id"],
                "race_name": race["name"],
                "race_time": race["time"],
                "number": top_pred["number"],
                "name": top_pred["name"],
                "prob": top_pred["prob"],
                "prob_diff": round(prob_diff, 3),
                "reason": f"ç¢ºç‡å·®{prob_diff:.1%} < {min_prob_diff:.0%}",
            }
            betting_picks["watch"].append(pick)

    return {
        "track": {
            "code": track_code,
            "name": TRACKS[track_code]['name'],
            "emoji": TRACKS[track_code]['emoji']
        },
        "date": request.date,
        "races": results,
        "betting_picks": betting_picks
    }


class RaceListRequest(BaseModel):
    track_code: str
    date: str


@app.post("/api/races")
def get_race_list(request: RaceListRequest):
    """ãƒ¬ãƒ¼ã‚¹ä¸€è¦§ã‚’å–å¾—ï¼ˆè»½é‡ï¼‰"""
    track_code = request.track_code
    date_str = request.date.replace("-", "")

    if track_code not in TRACKS:
        raise HTTPException(status_code=400, detail="ç„¡åŠ¹ãªç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰")

    scraper = NARScraper(track_code, delay=0.3)
    race_ids = scraper.get_race_list_by_date(date_str)

    return {
        "track": TRACKS[track_code],
        "race_ids": sorted(race_ids)
    }


class SingleRaceRequest(BaseModel):
    race_id: str
    track_code: str


@app.post("/api/predict/race")
def predict_single_race(request: SingleRaceRequest):
    """å˜ä¸€ãƒ¬ãƒ¼ã‚¹ã®äºˆæ¸¬"""
    race_id = request.race_id
    track_code = request.track_code

    if track_code not in TRACKS:
        raise HTTPException(status_code=400, detail="ç„¡åŠ¹ãªç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰")

    model, model_features, te_encoder, model_version, best_threshold = load_model(track_code)
    if model is None:
        raise HTTPException(
            status_code=400,
            detail=f"{TRACKS[track_code]['name']}ã®ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“"
        )

    # ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«å¿œã˜ãŸå‡¦ç†ã‚’é¸æŠ
    use_v8 = model_version == 'v8_no_leak'
    use_v3 = model_version == 'auto_optimized'

    scraper = NARScraper(track_code, delay=0.3)
    processor = Processor(te_encoder=te_encoder) if not (use_v3 or use_v8) else None

    df = scraper.get_race_data(race_id)
    if df is None:
        raise HTTPException(status_code=404, detail="ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“")

    df = scraper.enrich_data(df)

    # ã‚ªãƒƒã‚ºå–å¾—ï¼ˆv3ã§å¿…è¦ï¼‰
    all_odds = scraper.get_all_odds(race_id)
    win_odds_dict = all_odds.get('win', {})
    if 'horse_number' in df.columns:
        df['win_odds'] = df['horse_number'].apply(lambda x: win_odds_dict.get(int(x), 10) if pd.notna(x) else 10)

    # ç‰¹å¾´é‡ä½œæˆ
    if use_v8:
        df, features_to_use = create_features_v8(df)
    elif use_v3:
        df, features_to_use = create_features_v3(df)
    else:
        df = processor.process(df)
        features_to_use = model_features

    # è¤‡å‹ã‚ªãƒƒã‚ºå–å¾—
    place_odds_dict = all_odds.get('place', {})

    # äºˆæ¸¬
    X = df[features_to_use].fillna(-1)
    df['prob'] = predict_with_model(model, X)
    df['pred_rank'] = df['prob'].rank(ascending=False, method='min').astype(int)
    df = df.sort_values('prob', ascending=False)

    # ãƒ¬ãƒ¼ã‚¹æƒ…å ±
    race_num = race_id[-2:]
    race_name = df['race_name'].iloc[0] if 'race_name' in df.columns else f"{race_num}R"
    distance = int(df['distance'].iloc[0]) if 'distance' in df.columns else 0
    start_time = df['start_time'].iloc[0] if 'start_time' in df.columns else ""

    predictions = []
    for i, (_, row) in enumerate(df.iterrows()):  # å…¨é¦¬ã‚’è¿”ã™
        horse_num = int(row['horse_number']) if pd.notna(row.get('horse_number')) else 0
        win_odds = win_odds_dict.get(horse_num, 0)
        place_odds_data = place_odds_dict.get(horse_num, {})
        place_odds = place_odds_data.get('avg', 0) if place_odds_data else 0
        place_odds_min = place_odds_data.get('min', 0) if place_odds_data else 0
        place_odds_max = place_odds_data.get('max', 0) if place_odds_data else 0
        prob = float(row['prob'])

        # å‹ç‡ãƒ»è¤‡å‹ç‡ã‚’å–å¾—ï¼ˆ0-1ã®ç¯„å›²ã§ã‚ã‚‹ã¹ãï¼‰
        raw_win_rate = float(row.get('horse_win_rate') or 0)
        raw_show_rate = float(row.get('horse_show_rate') or 0)

        win_rate = raw_win_rate * 100
        show_rate = raw_show_rate * 100

        # æœŸå¾…å€¤è¨ˆç®—ï¼ˆè¤‡å‹ã‚ªãƒƒã‚º Ã— AIç¢ºç‡ï¼‰
        effective_place_odds = place_odds if place_odds > 0 else (win_odds / 3 if win_odds > 0 else 0)
        expected_value = prob * effective_place_odds if effective_place_odds > 0 else 0
        is_value = expected_value > 1.0

        # ========== å›åç‡ãƒ™ãƒ¼ã‚¹è²·ã„ç›®åˆ¤å®š ==========
        bet_layer = None
        recommended_bet = 0
        min_odds = MIN_PLACE_ODDS_FOR_ROI.get(track_code, 2.0)

        if i == 0:  # äºˆæ¸¬1ä½ã®ã¿å¯¾è±¡ï¼ˆãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã¨åŒã˜æ¡ä»¶ï¼‰
            if effective_place_odds >= min_odds:
                bet_layer = "roi_buy"
                recommended_bet = calculate_bet_amount(expected_value)
            elif effective_place_odds > 0:
                bet_layer = "watch"
                recommended_bet = 0

        predictions.append({
            "rank": i + 1,
            "number": horse_num,
            "name": row.get('horse_name', 'ä¸æ˜'),
            "jockey": row.get('jockey_name', 'ä¸æ˜'),
            "prob": round(prob, 3),
            "win_rate": round(win_rate, 1),
            "show_rate": round(show_rate, 1),
            "odds": win_odds,
            "place_odds": place_odds,
            "place_odds_min": place_odds_min,
            "place_odds_max": place_odds_max,
            "expected_value": round(expected_value, 2),
            "is_value": is_value,
            "bet_layer": bet_layer,
            "recommended_bet": recommended_bet
        })

    # äºˆæ¸¬ãƒ­ã‚°ã‚’ä¿å­˜ï¼ˆèª¤ç­”åˆ†æç”¨ï¼‰
    metadata = {
        "race_name": race_name,
        "distance": distance,
        "track_condition": df['track_condition'].iloc[0] if 'track_condition' in df.columns else "ä¸æ˜",
        "weather": df['weather'].iloc[0] if 'weather' in df.columns else "ä¸æ˜",
        "field_size": len(df)
    }
    save_prediction_log(race_id, track_code, predictions, metadata)

    # ========== å›åç‡ãƒ™ãƒ¼ã‚¹è²·ã„ç›®ã‚µãƒãƒªãƒ¼ï¼ˆå˜ä¸€ãƒ¬ãƒ¼ã‚¹ç”¨ï¼‰ ==========
    betting_picks = {
        "roi_buy": [],
        "watch": [],
        "total_bet": 0,
        "expected_return": 0,
        "min_odds_required": min_odds,
        "strategy": f"è¤‡å‹ã‚ªãƒƒã‚º{min_odds}å€ä»¥ä¸Šã®ã¿è³¼å…¥"
    }
    for pred in predictions:
        if pred["bet_layer"] in ["roi_buy", "watch"]:
            pick = {
                "number": pred["number"],
                "name": pred["name"],
                "prob": pred["prob"],
                "place_odds": pred["place_odds"],
                "expected_value": pred["expected_value"],
                "recommended_bet": pred["recommended_bet"],
                "reason": "ã‚ªãƒƒã‚ºæ¡ä»¶ã‚¯ãƒªã‚¢" if pred["bet_layer"] == "roi_buy" else f"ã‚ªãƒƒã‚º{min_odds}å€æœªæº€"
            }
            betting_picks[pred["bet_layer"]].append(pick)
            if pred["bet_layer"] == "roi_buy":
                betting_picks["total_bet"] += pred["recommended_bet"]
                betting_picks["expected_return"] += pred["recommended_bet"] * pred["expected_value"]

    return {
        "id": race_num,
        "name": race_name,
        "distance": distance,
        "time": start_time,
        "field_size": len(df),
        "predictions": predictions,
        "betting_picks": betting_picks
    }


# ========== è»½é‡ã‚ªãƒƒã‚ºå–å¾—API ==========

class OddsRequest(BaseModel):
    race_id: str
    track_code: str


def get_race_result(race_id: str) -> list:
    """ãƒ¬ãƒ¼ã‚¹çµæœï¼ˆç€é †ï¼‰ã‚’å–å¾—ï¼ˆã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯¾ç­–æ¸ˆã¿ï¼‰"""
    url = f"https://nar.netkeiba.com/race/result.html?race_id={race_id}"
    try:
        soup = fetch_with_retry(url, encoding='EUC-JP', delay=0.2)
        if not soup:
            return []

        results = []
        table = soup.find('table', class_='RaceTable01')
        if not table:
            table = soup.find('table', class_='Result_Table')
        if not table:
            return []

        for tr in table.find_all('tr'):
            tds = tr.find_all('td')
            if len(tds) < 3:
                continue

            rank_text = tds[0].get_text(strip=True)
            if not rank_text.isdigit():
                continue
            rank = int(rank_text)

            # é¦¬ç•ªã‚’å–å¾—ï¼ˆtds[2]ãŒé¦¬ç•ªã€tds[1]ã¯æ ç•ªï¼‰
            horse_num = None
            if len(tds) >= 3:
                umaban_text = tds[2].get_text(strip=True)
                if umaban_text.isdigit() and 1 <= int(umaban_text) <= 18:
                    horse_num = int(umaban_text)

            if horse_num:
                results.append({"rank": rank, "number": horse_num})

        return sorted(results, key=lambda x: x["rank"])[:3]  # TOP3ã®ã¿
    except:
        return []


@app.post("/api/odds")
def get_odds_only(request: OddsRequest):
    """ã‚ªãƒƒã‚ºã¨çµæœã‚’å–å¾—ï¼ˆãƒ¬ãƒ¼ã‚¹çµ‚äº†æ™‚ã¯çµæœã‚‚å«ã‚€ï¼‰"""
    race_id = request.race_id
    track_code = request.track_code

    if track_code not in TRACKS:
        raise HTTPException(status_code=400, detail="ç„¡åŠ¹ãªç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰")

    scraper = NARScraper(track_code, delay=0.2)

    # å˜å‹ãƒ»è¤‡å‹ã‚ªãƒƒã‚ºã‚’ä¸€æ‹¬å–å¾—
    all_odds = scraper.get_all_odds(race_id)
    win_odds = all_odds.get('win', {})
    place_odds = all_odds.get('place', {})

    # çµæœã‚‚å–å¾—ï¼ˆçµ‚äº†ã—ã¦ã„ã‚Œã°è¿”ã‚‹ã€ã¾ã ãªã‚‰ç©ºï¼‰
    result = get_race_result(race_id)

    return {
        "race_id": race_id,
        "odds": win_odds,
        "place_odds": place_odds,  # è¤‡å‹ã‚ªãƒƒã‚ºã‚’è¿½åŠ 
        "result": result if result else None
    }


# ========== äº‹å‰è¨ˆç®—æ¸ˆã¿äºˆæ¸¬å–å¾—API ==========

@app.get("/api/predictions/{date}/{track_code}")
def get_precomputed_predictions(date: str, track_code: str):
    """äº‹å‰è¨ˆç®—æ¸ˆã¿ã®äºˆæ¸¬JSONã‚’å–å¾—ï¼ˆå±¤åˆ¥è²·ã„ç›®ã‚’å‹•çš„ã«è¿½åŠ ï¼‰"""
    if track_code not in TRACKS:
        raise HTTPException(status_code=400, detail="ç„¡åŠ¹ãªç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰")

    predictions_file = BASE_DIR / "predictions" / date / f"{track_code}.json"

    if not predictions_file.exists():
        raise HTTPException(status_code=404, detail="äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

    import json
    with open(predictions_file, 'r', encoding='utf-8') as f:
        data = json.load(f)

    # å›åç‡ãƒ™ãƒ¼ã‚¹è²·ã„ç›®ã‚’å‹•çš„ã«è¿½åŠ ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã«å«ã¾ã‚Œã¦ã„ãªã„å ´åˆï¼‰
    min_odds = MIN_PLACE_ODDS_FOR_ROI.get(track_code, 2.0)

    for race in data.get("races", []):
        for i, pred in enumerate(race.get("predictions", [])):
            # bet_layerãŒã¾ã ãªã„å ´åˆã®ã¿è¿½åŠ 
            if "bet_layer" not in pred:
                bet_layer = None
                recommended_bet = 0

                if i == 0:  # äºˆæ¸¬1ä½ã®ã¿å¯¾è±¡
                    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ã¯ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚ªãƒƒã‚ºãŒãªã„ã®ã§ã€ã‚ªãƒƒã‚ºå–å¾—å¾Œã«å†åˆ¤å®šãŒå¿…è¦
                    place_odds = pred.get("place_odds", 0) or 0
                    expected_value = pred.get("expected_value", 0) or 0

                    if place_odds >= min_odds:
                        bet_layer = "roi_buy"
                        recommended_bet = calculate_bet_amount(expected_value)
                    else:
                        # ã‚ªãƒƒã‚ºæœªå–å¾— or ã‚ªãƒƒã‚ºä¸è¶³ â†’ æ§˜å­è¦‹
                        bet_layer = "watch"
                        recommended_bet = 0

                pred["bet_layer"] = bet_layer
                pred["recommended_bet"] = recommended_bet

    # betting_picksã‚µãƒãƒªãƒ¼ã‚’è¿½åŠ 
    data["betting_picks"] = {
        "roi_buy": [],
        "watch": [],
        "total_bet": 0,
        "expected_return": 0,
        "min_odds_required": min_odds,
        "strategy": f"è¤‡å‹ã‚ªãƒƒã‚º{min_odds}å€ä»¥ä¸Šã®ã¿è³¼å…¥"
    }
    for race in data.get("races", []):
        for pred in race.get("predictions", []):
            if pred.get("bet_layer") in ["roi_buy", "watch"]:
                pick = {
                    "race_id": race.get("id"),
                    "race_name": race.get("name"),
                    "race_time": race.get("time"),
                    "number": pred.get("number"),
                    "name": pred.get("name"),
                    "prob": pred.get("prob"),
                    "place_odds": pred.get("place_odds"),
                    "expected_value": pred.get("expected_value", 0),
                    "recommended_bet": pred.get("recommended_bet", 0),
                    "reason": "ã‚ªãƒƒã‚ºæ¡ä»¶ã‚¯ãƒªã‚¢" if pred["bet_layer"] == "roi_buy" else f"ã‚ªãƒƒã‚º{min_odds}å€æœªæº€ or æœªå–å¾—"
                }
                data["betting_picks"][pred["bet_layer"]].append(pick)
                if pred["bet_layer"] == "roi_buy":
                    data["betting_picks"]["total_bet"] += pred.get("recommended_bet", 0)
                    data["betting_picks"]["expected_return"] += pred.get("recommended_bet", 0) * pred.get("expected_value", 0)

    return data


@app.get("/api/predictions/{date}")
def list_available_predictions(date: str):
    """æŒ‡å®šæ—¥ã®åˆ©ç”¨å¯èƒ½ãªäºˆæ¸¬ä¸€è¦§"""
    predictions_dir = BASE_DIR / "predictions" / date

    if not predictions_dir.exists():
        return {"date": date, "tracks": []}

    available = []
    for f in predictions_dir.glob("*.json"):
        track_code = f.stem
        if track_code in TRACKS:
            available.append({
                "code": track_code,
                "name": TRACKS[track_code]['name'],
                "emoji": TRACKS[track_code]['emoji']
            })

    return {"date": date, "tracks": available}


# ========== ç²¾åº¦è©•ä¾¡API ==========

@app.get("/api/accuracy/{date}/{track_code}")
def get_accuracy(date: str, track_code: str):
    """æŒ‡å®šæ—¥ãƒ»ç«¶é¦¬å ´ã®ç²¾åº¦ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
    if track_code not in TRACKS:
        raise HTTPException(status_code=400, detail="ç„¡åŠ¹ãªç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰")

    accuracy_file = BASE_DIR / "accuracy" / date / f"{track_code}.json"

    if not accuracy_file.exists():
        raise HTTPException(status_code=404, detail="ç²¾åº¦ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

    import json
    with open(accuracy_file, 'r', encoding='utf-8') as f:
        data = json.load(f)

    return data


@app.get("/api/accuracy/{date}")
def get_daily_accuracy(date: str):
    """æŒ‡å®šæ—¥ã®å…¨ä½“ç²¾åº¦ã‚µãƒãƒªãƒ¼ã‚’å–å¾—"""
    summary_file = BASE_DIR / "accuracy" / date / "summary.json"

    if not summary_file.exists():
        raise HTTPException(status_code=404, detail="ç²¾åº¦ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

    import json
    with open(summary_file, 'r', encoding='utf-8') as f:
        data = json.load(f)

    return data


@app.get("/api/accuracy")
def get_accuracy_history():
    """éå»ã®ç²¾åº¦ãƒ‡ãƒ¼ã‚¿ä¸€è¦§ã‚’å–å¾—"""
    accuracy_dir = BASE_DIR / "accuracy"

    if not accuracy_dir.exists():
        return {"dates": []}

    dates = []
    for d in sorted(accuracy_dir.iterdir(), reverse=True):
        if d.is_dir():
            summary_file = d / "summary.json"
            if summary_file.exists():
                import json
                with open(summary_file, 'r', encoding='utf-8') as f:
                    summary = json.load(f)
                dates.append(summary)

    return {"history": dates[:30]}  # ç›´è¿‘30æ—¥åˆ†


# ========== ãƒ¢ãƒ‡ãƒ«æƒ…å ±API ==========

@app.get("/api/models/{track_code}")
def get_model_info(track_code: str):
    """ãƒ¢ãƒ‡ãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
    if track_code not in TRACKS:
        raise HTTPException(status_code=400, detail="ç„¡åŠ¹ãªç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰")

    model_path = TRACKS[track_code]['model']
    meta_path = model_path.replace('.pkl', '_meta.json')
    meta_file = BASE_DIR / meta_path

    result = None
    if meta_file.exists():
        import json
        with open(meta_file, 'r', encoding='utf-8') as f:
            result = json.load(f)
    else:
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿JSONãŒãªã„å ´åˆã€pklã‹ã‚‰èª­ã¿è¾¼ã¿è©¦è¡Œ
        model_file = BASE_DIR / model_path
        if model_file.exists():
            try:
                with open(model_file, 'rb') as f:
                    data = pickle.load(f)
                if 'metadata' in data:
                    result = data['metadata']
            except:
                pass

    if result is None:
        raise HTTPException(status_code=404, detail="ãƒ¢ãƒ‡ãƒ«æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“")

    # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ãŒæœŸå¾…ã™ã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¿½åŠ 
    if 'data_count' not in result:
        # CSVã‹ã‚‰ãƒ‡ãƒ¼ã‚¿æ•°ã‚’å–å¾—
        track_name = TRACKS[track_code]['model'].split('_')[1].replace('.pkl', '')
        csv_path = BASE_DIR / f'data/races_{track_name}.csv'
        if csv_path.exists():
            try:
                df = pd.read_csv(csv_path)
                result['data_count'] = len(df)
                # æ—¥ä»˜ç¯„å›²ã‚’å–å¾—
                if 'race_id' in df.columns:
                    race_ids = df['race_id'].astype(str)
                    dates = race_ids.str[0:4] + '-' + race_ids.str[6:8] + '-' + race_ids.str[8:10]
                    result['date_range'] = {
                        'from': dates.min(),
                        'to': dates.max()
                    }
            except:
                result['data_count'] = 0
                result['date_range'] = {'from': 'N/A', 'to': 'N/A'}
        else:
            result['data_count'] = 0
            result['date_range'] = {'from': 'N/A', 'to': 'N/A'}

    if 'date_range' not in result:
        result['date_range'] = {'from': 'N/A', 'to': 'N/A'}

    return result


@app.get("/api/models")
def get_all_models_info():
    """å…¨ãƒ¢ãƒ‡ãƒ«ã®æƒ…å ±ã‚’å–å¾—"""
    models_info = []

    for code, info in TRACKS.items():
        model_path = info['model']
        meta_path = model_path.replace('.pkl', '_meta.json')
        meta_file = BASE_DIR / meta_path
        model_file = BASE_DIR / model_path

        model_data = {
            "code": code,
            "name": info['name'],
            "emoji": info['emoji'],
            "model_exists": model_file.exists(),
            "metadata": None
        }

        if meta_file.exists():
            try:
                import json
                with open(meta_file, 'r', encoding='utf-8') as f:
                    model_data["metadata"] = json.load(f)
            except:
                pass

        models_info.append(model_data)

    return {"models": models_info}


# ========== èª¤ç­”åˆ†æAPIï¼ˆSSEå¯¾å¿œï¼‰ ==========

def analyze_get_race_result(race_id: str) -> list:
    """ãƒ¬ãƒ¼ã‚¹çµæœï¼ˆç€é †ï¼‰ã‚’å–å¾—ï¼ˆåˆ†æç”¨ãƒ»ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯¾ç­–æ¸ˆã¿ï¼‰"""
    url = f"https://nar.netkeiba.com/race/result.html?race_id={race_id}"
    try:
        soup = fetch_with_retry(url, encoding='EUC-JP', delay=0.3)
        if not soup:
            return []

        results = []
        table = soup.find('table', class_='RaceTable01')
        if not table:
            table = soup.find('table', class_='Result_Table')
        if not table:
            return []

        for tr in table.find_all('tr'):
            tds = tr.find_all('td')
            if len(tds) < 3:
                continue

            rank_text = tds[0].get_text(strip=True)
            if not rank_text.isdigit():
                continue
            rank = int(rank_text)

            umaban_text = tds[2].get_text(strip=True)
            if umaban_text.isdigit() and 1 <= int(umaban_text) <= 18:
                horse_num = int(umaban_text)
                results.append({"rank": rank, "number": horse_num})

        return sorted(results, key=lambda x: x["rank"])
    except Exception as e:
        print(f"Error fetching result for {race_id}: {e}")
        return []


def compare_prediction(prediction_log: dict, result: list) -> dict:
    """äºˆæ¸¬ã¨çµæœã‚’ç…§åˆ"""
    if not result:
        return None

    predictions = prediction_log["predictions"]
    metadata = prediction_log.get("metadata", {})

    pred_top3 = [p["number"] for p in predictions[:3]]
    pred_1st = predictions[0]["number"] if predictions else None
    actual_top3 = [r["number"] for r in result[:3]]
    actual_1st = result[0]["number"] if result else None

    win_hit = (pred_1st == actual_1st)
    show_hit = (pred_1st in actual_top3)

    # äºˆæ¸¬1ä½ã®é¦¬ãŒå®Ÿéš›ã«ä½•ç€ã ã£ãŸã‹
    pred_1st_actual_rank = None
    for r in result:
        if r["number"] == pred_1st:
            pred_1st_actual_rank = r["rank"]
            break

    # ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—åˆ†é¡
    error_type = None
    if not show_hit:
        if pred_1st_actual_rank is None:
            error_type = "å‡ºèµ°å–æ¶ˆ"
        elif pred_1st_actual_rank >= 10:
            error_type = "å¤§å¤–ã‚Œ(10ç€ä»¥ä¸‹)"
        elif pred_1st_actual_rank >= 6:
            error_type = "ä¸­å¤–ã‚Œ(6-9ç€)"
        elif pred_1st_actual_rank >= 4:
            error_type = "æƒœã—ã„(4-5ç€)"

    return {
        "race_id": prediction_log["race_id"],
        "track_name": prediction_log.get("track_name", "ä¸æ˜"),
        "race_name": metadata.get("race_name", "ä¸æ˜"),
        "pred_1st": pred_1st,
        "actual_1st": actual_1st,
        "win_hit": win_hit,
        "show_hit": show_hit,
        "pred_1st_actual_rank": pred_1st_actual_rank,
        "error_type": error_type,
        "metadata": metadata
    }


async def analyze_stream(date: str):
    """åˆ†æã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§å®Ÿè¡Œ"""
    log_dir = BASE_DIR / "prediction_logs" / date

    if not log_dir.exists():
        yield f"data: {json.dumps({'type': 'error', 'message': 'äºˆæ¸¬ãƒ­ã‚°ãŒã‚ã‚Šã¾ã›ã‚“'})}\n\n"
        return

    log_files = list(log_dir.glob("*.json"))
    total = len(log_files)

    if total == 0:
        yield f"data: {json.dumps({'type': 'error', 'message': 'äºˆæ¸¬ãƒ­ã‚°ãŒã‚ã‚Šã¾ã›ã‚“'})}\n\n"
        return

    yield f"data: {json.dumps({'type': 'start', 'total': total})}\n\n"

    comparisons = []
    for i, log_file in enumerate(log_files):
        with open(log_file, 'r', encoding='utf-8') as f:
            prediction_log = json.load(f)

        race_id = prediction_log["race_id"]

        # é€²æ—ã‚’é€ä¿¡
        yield f"data: {json.dumps({'type': 'progress', 'current': i + 1, 'total': total, 'race_id': race_id})}\n\n"

        # çµæœã‚’å–å¾—
        result = analyze_get_race_result(race_id)
        if result:
            comparison = compare_prediction(prediction_log, result)
            if comparison:
                comparisons.append(comparison)

        # å°‘ã—å¾…æ©Ÿï¼ˆã‚µãƒ¼ãƒãƒ¼è² è·è»½æ¸›ï¼‰
        await asyncio.sleep(0.3)

    # é›†è¨ˆ
    if not comparisons:
        yield f"data: {json.dumps({'type': 'error', 'message': 'ç…§åˆã§ãã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“'})}\n\n"
        return

    # çµ±è¨ˆã‚’è¨ˆç®—
    total_races = len(comparisons)
    win_hits = sum(1 for c in comparisons if c["win_hit"])
    show_hits = sum(1 for c in comparisons if c["show_hit"])

    # é¦¬å ´çŠ¶æ…‹åˆ¥
    by_track_condition = defaultdict(lambda: {"total": 0, "show_hits": 0})
    # å¤©æ°—åˆ¥
    by_weather = defaultdict(lambda: {"total": 0, "show_hits": 0})
    # è·é›¢åˆ¥
    by_distance = defaultdict(lambda: {"total": 0, "show_hits": 0})
    # ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—
    error_types = defaultdict(int)

    for c in comparisons:
        meta = c.get("metadata", {})

        # é¦¬å ´çŠ¶æ…‹
        track_cond = meta.get("track_condition", "ä¸æ˜")
        by_track_condition[track_cond]["total"] += 1
        if c["show_hit"]:
            by_track_condition[track_cond]["show_hits"] += 1

        # å¤©æ°—
        weather = meta.get("weather", "ä¸æ˜")
        by_weather[weather]["total"] += 1
        if c["show_hit"]:
            by_weather[weather]["show_hits"] += 1

        # è·é›¢
        distance = meta.get("distance", 0)
        if distance < 1400:
            dist_cat = "çŸ­è·é›¢(<1400m)"
        elif distance < 1800:
            dist_cat = "ä¸­è·é›¢(1400-1800m)"
        else:
            dist_cat = "é•·è·é›¢(>1800m)"
        by_distance[dist_cat]["total"] += 1
        if c["show_hit"]:
            by_distance[dist_cat]["show_hits"] += 1

        # ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—
        if c.get("error_type"):
            error_types[c["error_type"]] += 1

    # çµæœã‚’é€ä¿¡
    result_data = {
        "type": "result",
        "date": date,
        "summary": {
            "total_races": total_races,
            "win_hits": win_hits,
            "win_rate": round(win_hits / total_races * 100, 1) if total_races > 0 else 0,
            "show_hits": show_hits,
            "show_rate": round(show_hits / total_races * 100, 1) if total_races > 0 else 0
        },
        "by_track_condition": {k: v for k, v in by_track_condition.items()},
        "by_weather": {k: v for k, v in by_weather.items()},
        "by_distance": {k: v for k, v in by_distance.items()},
        "error_types": dict(error_types),
        "details": comparisons
    }

    yield f"data: {json.dumps(result_data, ensure_ascii=False)}\n\n"

    # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    output_dir = BASE_DIR / "analysis_reports" / date
    output_dir.mkdir(parents=True, exist_ok=True)
    output_file = output_dir / "report.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(result_data, f, ensure_ascii=False, indent=2)

    yield f"data: {json.dumps({'type': 'complete', 'saved_to': str(output_file)})}\n\n"


@app.get("/api/analyze/{date}")
def analyze_predictions(date: str):
    """äºˆæ¸¬ã®èª¤ç­”åˆ†æã‚’å®Ÿè¡Œï¼ˆé€šå¸¸APIç‰ˆï¼‰"""
    log_dir = BASE_DIR / "prediction_logs" / date

    if not log_dir.exists():
        raise HTTPException(status_code=404, detail="äºˆæ¸¬ãƒ­ã‚°ãŒã‚ã‚Šã¾ã›ã‚“")

    log_files = list(log_dir.glob("*.json"))
    total = len(log_files)

    if total == 0:
        raise HTTPException(status_code=404, detail="äºˆæ¸¬ãƒ­ã‚°ãŒã‚ã‚Šã¾ã›ã‚“")

    comparisons = []
    for log_file in log_files:
        with open(log_file, 'r', encoding='utf-8') as f:
            prediction_log = json.load(f)

        race_id = prediction_log["race_id"]

        # çµæœã‚’å–å¾—
        result = analyze_get_race_result(race_id)
        if result:
            comparison = compare_prediction(prediction_log, result)
            if comparison:
                comparisons.append(comparison)

        # ã‚µãƒ¼ãƒãƒ¼è² è·è»½æ¸›
        time.sleep(0.3)

    if not comparisons:
        raise HTTPException(status_code=404, detail="ç…§åˆã§ãã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

    # çµ±è¨ˆã‚’è¨ˆç®—
    total_races = len(comparisons)
    win_hits = sum(1 for c in comparisons if c["win_hit"])
    show_hits = sum(1 for c in comparisons if c["show_hit"])

    # é¦¬å ´çŠ¶æ…‹åˆ¥
    by_track_condition = defaultdict(lambda: {"total": 0, "show_hits": 0})
    by_weather = defaultdict(lambda: {"total": 0, "show_hits": 0})
    by_distance = defaultdict(lambda: {"total": 0, "show_hits": 0})
    error_types = defaultdict(int)

    for c in comparisons:
        meta = c.get("metadata", {})

        track_cond = meta.get("track_condition", "ä¸æ˜")
        by_track_condition[track_cond]["total"] += 1
        if c["show_hit"]:
            by_track_condition[track_cond]["show_hits"] += 1

        weather = meta.get("weather", "ä¸æ˜")
        by_weather[weather]["total"] += 1
        if c["show_hit"]:
            by_weather[weather]["show_hits"] += 1

        distance = meta.get("distance", 0)
        if distance < 1400:
            dist_cat = "çŸ­è·é›¢(<1400m)"
        elif distance < 1800:
            dist_cat = "ä¸­è·é›¢(1400-1800m)"
        else:
            dist_cat = "é•·è·é›¢(>1800m)"
        by_distance[dist_cat]["total"] += 1
        if c["show_hit"]:
            by_distance[dist_cat]["show_hits"] += 1

        if c.get("error_type"):
            error_types[c["error_type"]] += 1

    result_data = {
        "date": date,
        "summary": {
            "total_races": total_races,
            "win_hits": win_hits,
            "win_rate": round(win_hits / total_races * 100, 1) if total_races > 0 else 0,
            "show_hits": show_hits,
            "show_rate": round(show_hits / total_races * 100, 1) if total_races > 0 else 0
        },
        "by_track_condition": {k: v for k, v in by_track_condition.items()},
        "by_weather": {k: v for k, v in by_weather.items()},
        "by_distance": {k: v for k, v in by_distance.items()},
        "error_types": dict(error_types),
        "details": comparisons
    }

    # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    output_dir = BASE_DIR / "analysis_reports" / date
    output_dir.mkdir(parents=True, exist_ok=True)
    output_file = output_dir / "report.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(result_data, f, ensure_ascii=False, indent=2)

    return result_data


@app.get("/api/analysis/{date}")
def get_analysis_report(date: str):
    """ä¿å­˜æ¸ˆã¿ã®åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’å–å¾—"""
    report_file = BASE_DIR / "analysis_reports" / date / "report.json"

    if not report_file.exists():
        raise HTTPException(status_code=404, detail="åˆ†æãƒ¬ãƒãƒ¼ãƒˆãŒã‚ã‚Šã¾ã›ã‚“")

    with open(report_file, 'r', encoding='utf-8') as f:
        return json.load(f)


# ========== è²·ã„ç›®è¡¨ç¤ºHTML ==========
from fastapi.responses import HTMLResponse

@app.get("/betting/{track_code}/{date}", response_class=HTMLResponse)
def show_betting_picks(track_code: str, date: str):
    """è²·ã„ç›®ã‚’è¦‹ã‚„ã™ãè¡¨ç¤ºã™ã‚‹HTMLãƒšãƒ¼ã‚¸"""
    from pydantic import BaseModel

    class TempRequest(BaseModel):
        track_code: str
        date: str

    # äºˆæ¸¬ã‚’å®Ÿè¡Œ
    try:
        request = TempRequest(track_code=track_code, date=date)
        result = predict(PredictRequest(track_code=track_code, date=date))
    except Exception as e:
        return f"<html><body><h1>ã‚¨ãƒ©ãƒ¼</h1><p>{str(e)}</p></body></html>"

    track_info = result.get("track", {})
    betting = result.get("betting_picks", {})
    v6_buys = betting.get("v6_buy", [])
    watches = betting.get("watch", [])

    # HTMLç”Ÿæˆ
    html = f"""
<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{track_info.get('emoji', '')} {track_info.get('name', '')} è²·ã„ç›® - {date}</title>
    <style>
        * {{ box-sizing: border-box; margin: 0; padding: 0; }}
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            color: #eee;
            min-height: 100vh;
            padding: 20px;
        }}
        .container {{ max-width: 800px; margin: 0 auto; }}
        h1 {{
            text-align: center;
            margin-bottom: 10px;
            font-size: 1.8em;
        }}
        .strategy {{
            text-align: center;
            background: rgba(255,255,255,0.1);
            padding: 15px;
            border-radius: 10px;
            margin-bottom: 20px;
        }}
        .strategy .roi {{ color: #4ade80; font-size: 1.2em; font-weight: bold; }}
        .summary {{
            display: flex;
            justify-content: center;
            gap: 30px;
            margin-bottom: 30px;
            flex-wrap: wrap;
        }}
        .summary-item {{
            background: rgba(255,255,255,0.1);
            padding: 15px 25px;
            border-radius: 10px;
            text-align: center;
        }}
        .summary-item .value {{ font-size: 1.5em; font-weight: bold; color: #60a5fa; }}
        .section {{ margin-bottom: 30px; }}
        .section-title {{
            font-size: 1.3em;
            margin-bottom: 15px;
            padding-bottom: 10px;
            border-bottom: 2px solid #4ade80;
            display: flex;
            align-items: center;
            gap: 10px;
        }}
        .section-title.watch {{ border-bottom-color: #fbbf24; }}
        .pick-card {{
            background: rgba(255,255,255,0.05);
            border: 1px solid rgba(255,255,255,0.1);
            border-radius: 12px;
            padding: 15px 20px;
            margin-bottom: 12px;
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: 10px;
        }}
        .pick-card.buy {{
            border-left: 4px solid #4ade80;
            background: rgba(74, 222, 128, 0.1);
        }}
        .pick-card.watch {{
            border-left: 4px solid #fbbf24;
            background: rgba(251, 191, 36, 0.1);
        }}
        .race-info {{
            font-size: 0.9em;
            color: #9ca3af;
            min-width: 80px;
        }}
        .horse-info {{
            flex: 1;
            min-width: 150px;
        }}
        .horse-num {{
            display: inline-block;
            width: 30px;
            height: 30px;
            line-height: 30px;
            text-align: center;
            background: #3b82f6;
            border-radius: 50%;
            font-weight: bold;
            margin-right: 10px;
        }}
        .horse-name {{ font-weight: bold; font-size: 1.1em; }}
        .stats {{
            display: flex;
            gap: 15px;
            flex-wrap: wrap;
        }}
        .stat {{
            text-align: center;
            min-width: 60px;
        }}
        .stat-label {{ font-size: 0.75em; color: #9ca3af; }}
        .stat-value {{ font-weight: bold; }}
        .stat-value.high {{ color: #4ade80; }}
        .stat-value.medium {{ color: #60a5fa; }}
        .confidence {{
            padding: 5px 12px;
            border-radius: 20px;
            font-size: 0.85em;
            font-weight: bold;
        }}
        .confidence.high {{ background: #4ade80; color: #000; }}
        .confidence.medium {{ background: #60a5fa; color: #000; }}
        .no-picks {{
            text-align: center;
            padding: 40px;
            color: #9ca3af;
            font-size: 1.1em;
        }}
        .footer {{
            text-align: center;
            margin-top: 40px;
            padding: 20px;
            color: #6b7280;
            font-size: 0.9em;
        }}
    </style>
</head>
<body>
    <div class="container">
        <h1>{track_info.get('emoji', '')} {track_info.get('name', '')} è²·ã„ç›®</h1>
        <p style="text-align:center; color:#9ca3af; margin-bottom:20px;">{date}</p>

        <div class="strategy">
            <p>æˆ¦ç•¥: <span class="roi">{betting.get('strategy', '')}</span></p>
        </div>

        <div class="summary">
            <div class="summary-item">
                <div class="stat-label">æ¨å¥¨è²·ã„ç›®</div>
                <div class="value">{len(v6_buys)}R</div>
            </div>
            <div class="summary-item">
                <div class="stat-label">åˆè¨ˆè³­ã‘é‡‘</div>
                <div class="value">Â¥{betting.get('total_bet', 0):,}</div>
            </div>
            <div class="summary-item">
                <div class="stat-label">æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³</div>
                <div class="value" style="color:#4ade80;">Â¥{int(betting.get('expected_return', 0)):,}</div>
            </div>
        </div>
"""

    # è²·ã„ç›®ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    if v6_buys:
        html += """
        <div class="section">
            <div class="section-title">ğŸ¯ è²·ã„ç›®ï¼ˆè¤‡å‹ï¼‰</div>
"""
        for pick in v6_buys:
            conf_class = "high" if pick.get("confidence") == "é«˜" else "medium"
            html += f"""
            <div class="pick-card buy">
                <div class="race-info">
                    <div>{pick.get('race_id', '')}R</div>
                    <div>{pick.get('race_time', '')}</div>
                </div>
                <div class="horse-info">
                    <span class="horse-num">{pick.get('number', '')}</span>
                    <span class="horse-name">{pick.get('name', '')}</span>
                </div>
                <div class="stats">
                    <div class="stat">
                        <div class="stat-label">AIç¢ºç‡</div>
                        <div class="stat-value high">{pick.get('prob', 0):.1%}</div>
                    </div>
                    <div class="stat">
                        <div class="stat-label">ç¢ºç‡å·®</div>
                        <div class="stat-value medium">{pick.get('prob_diff', 0):.1%}</div>
                    </div>
                    <div class="stat">
                        <div class="stat-label">å˜å‹</div>
                        <div class="stat-value">{pick.get('odds', 0)}å€</div>
                    </div>
                </div>
                <span class="confidence {conf_class}">{pick.get('confidence', 'ä¸­')}</span>
            </div>
"""
        html += "</div>"
    else:
        html += '<div class="no-picks">ğŸ¤” æœ¬æ—¥ã¯æ¨å¥¨è²·ã„ç›®ãŒã‚ã‚Šã¾ã›ã‚“</div>'

    # æ§˜å­è¦‹ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    if watches:
        html += """
        <div class="section">
            <div class="section-title watch">ğŸ‘€ æ§˜å­è¦‹ï¼ˆç¢ºç‡å·®ä¸è¶³ï¼‰</div>
"""
        for pick in watches[:5]:  # æœ€å¤§5ä»¶
            html += f"""
            <div class="pick-card watch">
                <div class="race-info">
                    <div>{pick.get('race_id', '')}R</div>
                    <div>{pick.get('race_time', '')}</div>
                </div>
                <div class="horse-info">
                    <span class="horse-num">{pick.get('number', '')}</span>
                    <span class="horse-name">{pick.get('name', '')}</span>
                </div>
                <div class="stats">
                    <div class="stat">
                        <div class="stat-label">AIç¢ºç‡</div>
                        <div class="stat-value">{pick.get('prob', 0):.1%}</div>
                    </div>
                    <div class="stat">
                        <div class="stat-label">ç¢ºç‡å·®</div>
                        <div class="stat-value" style="color:#fbbf24;">{pick.get('prob_diff', 0):.1%}</div>
                    </div>
                </div>
                <span style="color:#9ca3af; font-size:0.85em;">{pick.get('reason', '')}</span>
            </div>
"""
        html += "</div>"

    html += f"""
        <div class="footer">
            <p>v6 é¸æŠçš„ãƒ™ãƒƒãƒ†ã‚£ãƒ³ã‚°æˆ¦ç•¥</p>
            <p>æœŸå¾…ROI: å¤§äº•105.7% / å·å´114.7%</p>
        </div>
    </div>
</body>
</html>
"""
    return HTMLResponse(content=html)


@app.get("/betting", response_class=HTMLResponse)
def betting_index():
    """è²·ã„ç›®ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸"""
    today = datetime.now().strftime("%Y-%m-%d")
    html = f"""
<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç«¶é¦¬AI è²·ã„ç›®</title>
    <style>
        body {{
            font-family: -apple-system, BlinkMacSystemFont, sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            color: #eee;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            padding: 20px;
        }}
        h1 {{ margin-bottom: 30px; }}
        .tracks {{
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(150px, 1fr));
            gap: 15px;
            max-width: 600px;
            width: 100%;
        }}
        a {{
            display: block;
            background: rgba(255,255,255,0.1);
            padding: 20px;
            border-radius: 12px;
            text-decoration: none;
            color: #fff;
            text-align: center;
            transition: all 0.3s;
        }}
        a:hover {{
            background: rgba(255,255,255,0.2);
            transform: translateY(-3px);
        }}
        .emoji {{ font-size: 2em; display: block; margin-bottom: 10px; }}
    </style>
</head>
<body>
    <h1>ğŸ‡ ç«¶é¦¬AI è²·ã„ç›®</h1>
    <p style="margin-bottom:20px; color:#9ca3af;">{today}</p>
    <div class="tracks">
"""
    for code, info in TRACKS.items():
        html += f'<a href="/betting/{code}/{today}"><span class="emoji">{info["emoji"]}</span>{info["name"]}</a>\n'

    html += """
    </div>
</body>
</html>
"""
    return HTMLResponse(content=html)


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
